{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "def d(l):\n",
    "    return tokenizer.batch_decode(l,skip_special_tokens=True)\n",
    "def en(l):\n",
    "    return tokenize(l,tokenizer,512,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en(['.'])\n",
    "label = en(['Sehr geehrte Kollegen! Ich danke Frau Schroedter für den fundierten Bericht.', 'Sie hat sich eingehend mit der Problematik beschäftigt und während der Behandlung im Ausschuß viele zu dem vorliegenden Bericht eingegangene nderungsanträge berücksichtigt.'])\n",
    "pred = en(['Herr Kommissar, ich möchte Frau Schroedter für einen ausgezeichneten Bericht danken.', 'Sie hat in der Aussprache im Ausschuss viele der nderungsanträge berücksichtigt, die zu diesem Bericht eingereicht wurden.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model/D_A.pt').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    3, 18976,   873,  7392,    17,    15, 23420,    55,  1674, 12957,\n",
      "            15,  7672,   180, 10363,    15,    26,   449,   218,   177,  3069,\n",
      "          6305, 19146,     5,     1,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  292,     3,   547,   289,   236,  8615,    26,   181,    74,  5289,\n",
      "             9,  4414, 23029,    64,     3,  5729,    74, 12196,   256,  1392,\n",
      "           860,  6712,  2584,   170,   340,   426, 22646, 19146,   236, 16416,\n",
      "            15,     3, 20181,     7,   288,  7921,   397, 29699,     5,     1]],\n",
      "       device='cuda:0')\n",
      "torch.Size([2, 40])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "\t\t---------embedding\n",
      "torch.Size([2, 40, 512])\n",
      "tensor([[[ 11.2275,   8.0182,  14.2276,  ...,   9.7521,  -7.9230,  -3.6829],\n",
      "         [-20.6552, -14.6285,  -2.9490,  ..., -33.5719,  28.3649,  27.1788],\n",
      "         [ 18.0808, -13.7200,   3.7330,  ...,   4.7249,  32.9982,   1.0902],\n",
      "         ...,\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691],\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691],\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691]],\n",
      "\n",
      "        [[ -9.1765,  -7.9843,  17.2429,  ...,  18.7044,  16.9157,  18.5393],\n",
      "         [ 11.2275,   8.0182,  14.2276,  ...,   9.7521,  -7.9230,  -3.6829],\n",
      "         [ 15.2374,  -6.6709, -12.6626,  ...,   3.4055,  -7.8125,  -6.7354],\n",
      "         ...,\n",
      "         [ -9.9194,  -5.6020,  -3.0875,  ..., -15.7126,  -1.7929,   7.8536],\n",
      "         [ -4.3322,   7.3662, -14.5843,  ...,  13.0421,  -2.7197,  -3.1223],\n",
      "         [ 12.6452,   8.1971, -11.5302,  ...,   7.8170,  -7.2924,   0.9600]]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
      "\t\t---------encode\n",
      "torch.Size([2, 40, 512])\n",
      "tensor([[[ 1.6078e-02, -1.3255e-03, -3.7461e-01,  ..., -1.3444e-01,\n",
      "           1.5916e-02, -6.3450e-03],\n",
      "         [-9.2823e-02,  4.5944e-02, -8.3879e-02,  ..., -2.6461e-01,\n",
      "           2.3039e-01, -7.9949e-03],\n",
      "         [-1.2245e-01,  9.4419e-02, -2.4199e-01,  ..., -2.5454e-02,\n",
      "           1.6725e-01, -1.5961e-01],\n",
      "         ...,\n",
      "         [ 1.6117e-01,  5.3436e-02,  2.2179e-01,  ..., -2.0456e-02,\n",
      "           1.5226e-03, -2.0461e-01],\n",
      "         [ 1.4894e-01,  5.5903e-02,  2.2576e-01,  ..., -1.6650e-02,\n",
      "          -1.7260e-04, -2.1847e-01],\n",
      "         [ 1.5109e-01,  5.9630e-02,  2.4501e-01,  ..., -3.3215e-02,\n",
      "           3.5086e-04, -2.1819e-01]],\n",
      "\n",
      "        [[-4.3857e-02, -3.1801e-01, -3.6142e-02,  ..., -1.0341e-01,\n",
      "          -1.2573e-01,  1.0433e-01],\n",
      "         [ 2.3509e-02, -1.0648e-01, -2.9341e-01,  ..., -1.4453e-01,\n",
      "          -1.3130e-01, -1.1776e-01],\n",
      "         [ 7.0534e-02, -2.2883e-01, -3.8468e-01,  ..., -2.5613e-01,\n",
      "           3.2515e-02,  1.2224e-01],\n",
      "         ...,\n",
      "         [-8.4147e-02, -7.9999e-03,  9.4171e-02,  ..., -1.2250e-01,\n",
      "          -1.4593e-01,  3.6734e-01],\n",
      "         [-1.1325e-01,  1.1561e-01, -1.0740e-01,  ...,  4.1098e-02,\n",
      "          -2.3893e-02,  3.6458e-03],\n",
      "         [ 1.3706e-01,  7.0807e-02, -8.4081e-02,  ..., -8.5971e-02,\n",
      "           2.4742e-02,  1.2627e-02]]], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\t\t---------mask the vector\n",
      "torch.Size([2, 40, 512])\n",
      "tensor([[[ 0.0161, -0.0013, -0.3746,  ..., -0.1344,  0.0159, -0.0063],\n",
      "         [-0.0928,  0.0459, -0.0839,  ..., -0.2646,  0.2304, -0.0080],\n",
      "         [-0.1224,  0.0944, -0.2420,  ..., -0.0255,  0.1673, -0.1596],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0439, -0.3180, -0.0361,  ..., -0.1034, -0.1257,  0.1043],\n",
      "         [ 0.0235, -0.1065, -0.2934,  ..., -0.1445, -0.1313, -0.1178],\n",
      "         [ 0.0705, -0.2288, -0.3847,  ..., -0.2561,  0.0325,  0.1222],\n",
      "         ...,\n",
      "         [-0.0841, -0.0080,  0.0942,  ..., -0.1225, -0.1459,  0.3673],\n",
      "         [-0.1133,  0.1156, -0.1074,  ...,  0.0411, -0.0239,  0.0036],\n",
      "         [ 0.1371,  0.0708, -0.0841,  ..., -0.0860,  0.0247,  0.0126]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\t\t---------mean of the unmask \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_256080/2048363798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t\\t---------mean of the unmask '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mdistr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#real sentences\n",
    "x = label[0].cuda()\n",
    "#delte 0 give huge diff\n",
    "       \n",
    "# x = torch.Tensor(x).long().cuda()\n",
    "print(x)\n",
    "print(x.shape)\n",
    "x_attn = (x>0.5).long()\n",
    "\n",
    "print('\\t\\t---------embedding')\n",
    "x_emb = model.embedding(x)\n",
    "print(x_emb.shape)\n",
    "print(x_emb)# same for padding\n",
    "\n",
    "print('\\t\\t---------encode')\n",
    "distr = model.encoder(inputs_embeds=x_emb,attention_mask=x_attn).last_hidden_state#(bs,sentence length,512)\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "print('\\t\\t---------mask the vector')\n",
    "x_attn_unsq= x_attn.unsqueeze(-1)\n",
    "distr = torch.mul(distr,x_attn_unsq)#previously\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "\n",
    "print('\\t\\t---------mean of the unmask ')\n",
    "distr = torch.sum(distr,1)/torch.sum(x_attn,1)\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "print('\\t\\t---------classifer ')\n",
    "ret =  model.classifier(distr)#(bs,1)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 31])\n",
      "\t\t---------embedding\n",
      "torch.Size([2, 31, 512])\n",
      "tensor([[[-21.8447, -25.4242,  -1.9711,  ...,  14.6676,  42.0918,  13.0946],\n",
      "         [ 14.2375,  -0.1345,  11.7293,  ...,  31.9208,  14.0575,   8.5395],\n",
      "         [  5.0407, -21.2402,   6.1542,  ...,  38.0355,  10.9177,  38.7281],\n",
      "         ...,\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691],\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691],\n",
      "         [ -1.9703,   0.1800,  -7.0921,  ...,  -0.4834,   2.7068,  -2.8691]],\n",
      "\n",
      "        [[ -9.1765,  -7.9843,  17.2429,  ...,  18.7044,  16.9157,  18.5393],\n",
      "         [ 11.2275,   8.0182,  14.2276,  ...,   9.7521,  -7.9230,  -3.6829],\n",
      "         [ 15.2374,  -6.6709, -12.6626,  ...,   3.4055,  -7.8125,  -6.7354],\n",
      "         ...,\n",
      "         [ 15.8901, -35.9702, -16.5363,  ..., -29.2687,   1.1392,   2.1299],\n",
      "         [ -4.3322,   7.3662, -14.5843,  ...,  13.0421,  -2.7197,  -3.1223],\n",
      "         [ 12.6452,   8.1971, -11.5302,  ...,   7.8170,  -7.2924,   0.9600]]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
      "\t\t---------encode\n",
      "torch.Size([2, 31, 512])\n",
      "tensor([[[-0.0900, -0.0361, -0.2592,  ..., -0.3171,  0.1958, -0.2517],\n",
      "         [-0.1146, -0.1346, -0.1963,  ..., -0.0421,  0.0320, -0.2920],\n",
      "         [-0.0404, -0.0370, -0.2026,  ..., -0.0701, -0.0126, -0.3964],\n",
      "         ...,\n",
      "         [ 0.2183,  0.0447,  0.1784,  ..., -0.0345, -0.0406, -0.1620],\n",
      "         [ 0.2114,  0.0440,  0.1776,  ..., -0.0410, -0.0417, -0.1654],\n",
      "         [ 0.2154,  0.0448,  0.1656,  ..., -0.0491, -0.0448, -0.1623]],\n",
      "\n",
      "        [[-0.0014, -0.2384, -0.0462,  ..., -0.0527, -0.1789,  0.0844],\n",
      "         [ 0.1350,  0.0037, -0.2389,  ..., -0.1500, -0.1958, -0.0138],\n",
      "         [ 0.1382, -0.0701, -0.5130,  ..., -0.2831, -0.0170,  0.3297],\n",
      "         ...,\n",
      "         [-0.0254, -0.0166, -0.4048,  ..., -0.1511,  0.0825,  0.2388],\n",
      "         [-0.1056,  0.1682, -0.0095,  ...,  0.1048, -0.0539, -0.0120],\n",
      "         [ 0.1340,  0.0887, -0.0671,  ..., -0.0583,  0.0244,  0.0361]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\t\t---------mask the vector\n",
      "torch.Size([2, 31, 512])\n",
      "tensor([[[-0.0900, -0.0361, -0.2592,  ..., -0.3171,  0.1958, -0.2517],\n",
      "         [-0.1146, -0.1346, -0.1963,  ..., -0.0421,  0.0320, -0.2920],\n",
      "         [-0.0404, -0.0370, -0.2026,  ..., -0.0701, -0.0126, -0.3964],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0014, -0.2384, -0.0462,  ..., -0.0527, -0.1789,  0.0844],\n",
      "         [ 0.1350,  0.0037, -0.2389,  ..., -0.1500, -0.1958, -0.0138],\n",
      "         [ 0.1382, -0.0701, -0.5130,  ..., -0.2831, -0.0170,  0.3297],\n",
      "         ...,\n",
      "         [-0.0254, -0.0166, -0.4048,  ..., -0.1511,  0.0825,  0.2388],\n",
      "         [-0.1056,  0.1682, -0.0095,  ...,  0.1048, -0.0539, -0.0120],\n",
      "         [ 0.1340,  0.0887, -0.0671,  ..., -0.0583,  0.0244,  0.0361]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n",
      "\t\t---------mean of the unmask \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_256080/3907246072.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t\\t---------mean of the unmask '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdistr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_attn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#real sentences\n",
    "x = pred[0].cuda()\n",
    "       \n",
    "# x = torch.Tensor(x).long().cuda()\n",
    "print(x.shape)\n",
    "x_attn = (x>0.5).long()\n",
    "\n",
    "print('\\t\\t---------embedding')\n",
    "x_emb = model.embedding(x)\n",
    "print(x_emb.shape)\n",
    "print(x_emb)# same for padding\n",
    "\n",
    "print('\\t\\t---------encode')\n",
    "distr = model.encoder(inputs_embeds=x_emb,attention_mask=x_attn).last_hidden_state#(bs,sentence length,512)\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "print('\\t\\t---------mask the vector')\n",
    "x_attn_unsq= x_attn.unsqueeze(-1)\n",
    "distr = torch.mul(distr,x_attn_unsq)#previously\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "\n",
    "print('\\t\\t---------mean of the unmask ')\n",
    "print(torch.sum(distr,1).shape)\n",
    "distr = torch.sum(distr,1)/torch.sum(x_attn,1)\n",
    "print(distr.shape)\n",
    "print(distr)\n",
    "\n",
    "print('\\t\\t---------classifer ')\n",
    "ret =  model.classifier(distr)#(bs,1)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9008]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# x_emb = model.embedding(x_)#\n",
    "# print('x_emb.shape',x_emb.shape)\n",
    "# distr = model.encoder(inputs_embeds=x_emb).last_hidden_state#(bs,sentence length,512)\n",
    "# print('distr.shape',distr.shape)\n",
    "# x_attn= x_attn.unsqueeze(-1)\n",
    "# print('x_attn.shape',x_attn.shape)\n",
    "# distr = torch.mul(distr,x_attn)#previously\n",
    "\n",
    "# print('mutil',torch.sum(distr,1))\n",
    "# print('count',torch.sum(x_attn,1))\n",
    "# distr = torch.sum(distr,1)/torch.sum(x_attn,1)#(bs,512)\n",
    "# print(torch.mean(distr,-1))\n",
    "# print('mea',distr.shape)\n",
    "\n",
    "# ret =  model.classifier(distr)#(bs,1)\n",
    "# print(ret)\n",
    "# ret = model.relu(ret)#(bs,1)\n",
    "# print(ret)\n",
    "\n",
    "\n",
    "\n",
    "a_pred_dis = model(x_,x_attn)\n",
    "a_pred_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ",attention_mask=x_attn is essential for the encoder inpuit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We previously use torch.mean to (x after embedding)*x_attn but the mean will be small for the long sentences, now we use torch.sum(distr,1)/torch.sum(x_attn,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see that the D judge the sentence by it's length\n",
    "## small output for the first part, but large for the latter part, so the longer the higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so we change the output to [batch,0,512] ie, onlythe first word's sumQ*V and than droppout and then classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
