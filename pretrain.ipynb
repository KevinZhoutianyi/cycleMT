{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset,load_metric\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import time\n",
    "from transformers.optimization import Adafactor\n",
    "import os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "max_length= 512\n",
    "test_step = 1000\n",
    "report_step = 100\n",
    "seed = 2\n",
    "bs =4 \n",
    "lr = 1e-4\n",
    "train_num = 1000\n",
    "valid_num = 200\n",
    "\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "\n",
    "# Setting the seeds\n",
    "np.random.seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "# model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# input_ids = tokenizer(\"translate English to German: The house is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "# labels = tokenizer(\"Das Haus ist wunderbar.\", return_tensors=\"pt\").input_ids\n",
    "# loss = model(input_ids=input_ids, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgrageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val*n #TODO:its just for W\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "\n",
    "def tokenize(text_data, tokenizer, max_length, padding = True):\n",
    "    \n",
    "    encoding = tokenizer(text_data, return_tensors='pt', padding=padding, truncation = True, max_length = max_length)\n",
    "\n",
    "    input_ids = encoding['input_ids']\n",
    "    \n",
    "    attention_mask = encoding['attention_mask']\n",
    "    \n",
    "    return input_ids, attention_mask\n",
    "def get_Dataset(dataset, tokenizer):\n",
    "    train_sentence = [x['de'] for x in dataset]\n",
    "    train_target = [x['en'] for x in dataset]\n",
    "\n",
    "  \n",
    "    model1_input_ids, model1_input_attention_mask = tokenize(train_sentence, tokenizer, max_length = max_length)\n",
    "  \n",
    "    model1_target_ids, model1_target_attention_mask = tokenize(train_target, tokenizer, max_length = max_length)\n",
    " \n",
    "    train_data = TensorDataset(model1_input_ids, model1_input_attention_mask, model1_target_ids, model1_target_attention_mask)\n",
    "   \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "optimizer = Adafactor(model.parameters(), lr = lr ,scale_parameter=False, relative_step=False , warmup_init=False,clip_threshold=1,beta1=0,eps=( 1e-30,0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/20 08:32:45 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 37.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset('wmt16','de-en')\n",
    "# dataset = dataset.shuffle(seed=2)\n",
    "train = dataset['train']['translation'][:train_num]\n",
    "valid = dataset['train']['translation'][train_num:(train_num+valid_num)]\n",
    "\n",
    "def preprocess(dat):\n",
    "    for t in dat:\n",
    "        t['de'] = \"translate German to English: \" + t['de']  #needed for T5\n",
    "preprocess(train)\n",
    "preprocess(valid)\n",
    "\n",
    "train_data = get_Dataset(train, tokenizer)\n",
    "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data), \n",
    "                        batch_size=bs, pin_memory=True, num_workers=4)\n",
    "valid_data = get_Dataset(valid, tokenizer)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=bs, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(_dataloader,model,optimizer):\n",
    "    objs = AvgrageMeter()\n",
    "    for step,batch in enumerate(_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        train_x = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_x_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        train_y = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)    \n",
    "        train_y_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)    \n",
    "        train_y[train_y == tokenizer.pad_token_id] = -100\n",
    "        loss = model(input_ids=train_x, attention_mask=train_x_attn, labels=train_y).loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        objs.update(loss.item(), bs)\n",
    "        if(step%report_step==0 and step!=0):\n",
    "            logging.info(f'step:{step}\\t,avgloss:{objs.avg}')\n",
    "            objs.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "@torch.no_grad()\n",
    "def my_test(_dataloader,model,epoch):\n",
    "    # logging.info(f\"GPU mem before test:{getGPUMem(device)}%\")\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    metric_sacrebleu =  load_metric('sacrebleu')\n",
    "    metric_bleu =  load_metric('bleu')\n",
    "\n",
    "    # for step, batch in enumerate(tqdm(_dataloader,desc =\"test for epoch\"+str(epoch))):\n",
    "    for step, batch in enumerate(_dataloader):\n",
    "        \n",
    "        test_dataloaderx = Variable(batch[0], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloaderx_attn = Variable(batch[1], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery = Variable(batch[2], requires_grad=False).to(device, non_blocking=False)\n",
    "        test_dataloadery_attn = Variable(batch[3], requires_grad=False).to(device, non_blocking=False)\n",
    "        target_ids = copy.deepcopy(test_dataloadery)\n",
    "        target_ids[target_ids == tokenizer.pad_token_id] = -100\n",
    "        ls = model(input_ids=test_dataloaderx, attention_mask=test_dataloaderx_attn, labels=target_ids).loss\n",
    "        acc+= ls.item()\n",
    "        counter+= 1\n",
    "        pre = model.generate(test_dataloaderx)\n",
    "        x_decoded = tokenizer.batch_decode(test_dataloaderx,skip_special_tokens=True)\n",
    "        pred_decoded = tokenizer.batch_decode(pre,skip_special_tokens=True)\n",
    "        label_decoded =  tokenizer.batch_decode(test_dataloadery,skip_special_tokens=True)\n",
    "        \n",
    "        pred_str = [x  for x in pred_decoded]\n",
    "        label_str = [[x] for x in label_decoded]\n",
    "        pred_list = [x.split()  for x in pred_decoded]\n",
    "        label_list = [[x.split()] for x in label_decoded]\n",
    "        metric_sacrebleu.add_batch(predictions=pred_str, references=label_str)\n",
    "        metric_bleu.add_batch(predictions=pred_list, references=label_list)\n",
    "        if  step%100==0:\n",
    "            logging.info(f'x_decoded[:2]:{x_decoded[:2]}')\n",
    "            logging.info(f'pred_decoded[:2]:{pred_decoded[:2]}')\n",
    "            logging.info(f'label_decoded[:2]:{label_decoded[:2]}')\n",
    "            \n",
    "            \n",
    "    sacrebleu_score = metric_sacrebleu.compute()\n",
    "    bleu_score = metric_bleu.compute()\n",
    "    logging.info('sacreBLEU : %f',sacrebleu_score['score'])#TODO:bleu may be wrong cuz max length\n",
    "    logging.info('BLEU : %f',bleu_score['bleu'])\n",
    "    logging.info('test loss : %f',acc/(counter))\n",
    "    \n",
    "    del test_dataloaderx,acc,counter,test_dataloaderx_attn,sacrebleu_score,bleu_score,test_dataloadery,test_dataloadery_attn,ls,pre,x_decoded,pred_decoded,label_decoded,pred_str,label_str,pred_list,label_list\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    # logging.info(f\"GPU mem after test:{getGPUMem(device)}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/20 08:46:53 PM |\t  x_decoded[:2]:['translate German to English: Betrifft: Einbeziehung der Gleichstellungspolitik in die gemeinschaftliche Beihilfepolitik Der Rat hat bereits 1995 Leitlinien für die Integrierung des Gleichstellungsaspekts in die gesamte gemeinschaftliche Beihilfepolitik ausgearbeitet.', 'translate German to English: Die Leitlinien verlangen, daß alle Mitarbeiter, die mit Entwicklungsfragen befaßt sind, kontinuierlich in der Gleichstellungsproblematik weitergebildet werden. In den letzten zwei Jahren haben aber nur rund 50 Personen an dieser Ausbildung teilgenommen, und in der GD Entwicklung gibt es noch immer keine obligatorische Schulung im Bereich Gleichstellung.']\n",
      "04/20 08:46:53 PM |\t  pred_decoded[:2]:['Concerning the integration of the equality policy in the Community Assistance Policy The Council has already developed guidelines', 'The guidelines have long been that all staff who have developed issues will continue to be able to']\n",
      "04/20 08:46:53 PM |\t  label_decoded[:2]:[\"Subject: 'Mainstreaming' in EU aid policy In 1995 the Council drew up guidelines for integrating the equal opportunities dimension ('mainstreaming') into the full range of EU aid policy.\", \"The guidelines call for all staff working in the development sector to receive continuous training in 'gender mainstreaming' but in recent years only around 50 people have been trained and there is still no compulsory training in the subject within the Directorate-General for Development.\"]\n",
      "04/20 08:47:06 PM |\t  sacreBLEU : 6.102927\n",
      "04/20 08:47:06 PM |\t  BLEU : 0.050357\n",
      "04/20 08:47:06 PM |\t  test loss : 2.196072\n",
      "04/20 08:47:07 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "04/20 08:47:23 PM |\t  step:100\t,avgloss:2.0922457304331337\n",
      "04/20 08:47:37 PM |\t  step:200\t,avgloss:2.1860923731327055\n",
      "04/20 08:47:50 PM |\t  step:300\t,avgloss:2.144693623781204\n",
      "04/20 08:48:05 PM |\t  step:400\t,avgloss:2.0824443280696867\n",
      "04/20 08:48:19 PM |\t  step:500\t,avgloss:2.124786737859249\n",
      "04/20 08:48:33 PM |\t  step:600\t,avgloss:2.2919200241565703\n",
      "04/20 08:48:46 PM |\t  step:700\t,avgloss:2.324466770887375\n",
      "04/20 08:49:08 PM |\t  x_decoded[:2]:['translate German to English: Betrifft: Einbeziehung der Gleichstellungspolitik in die gemeinschaftliche Beihilfepolitik Der Rat hat bereits 1995 Leitlinien für die Integrierung des Gleichstellungsaspekts in die gesamte gemeinschaftliche Beihilfepolitik ausgearbeitet.', 'translate German to English: Die Leitlinien verlangen, daß alle Mitarbeiter, die mit Entwicklungsfragen befaßt sind, kontinuierlich in der Gleichstellungsproblematik weitergebildet werden. In den letzten zwei Jahren haben aber nur rund 50 Personen an dieser Ausbildung teilgenommen, und in der GD Entwicklung gibt es noch immer keine obligatorische Schulung im Bereich Gleichstellung.']\n",
      "04/20 08:49:08 PM |\t  pred_decoded[:2]:['Concerning the integration of the equality policy in the Community aid policy The Council has already drafted', 'The guidelines require that all staff who are involved in development issues continue to be involved in the issue']\n",
      "04/20 08:49:08 PM |\t  label_decoded[:2]:[\"Subject: 'Mainstreaming' in EU aid policy In 1995 the Council drew up guidelines for integrating the equal opportunities dimension ('mainstreaming') into the full range of EU aid policy.\", \"The guidelines call for all staff working in the development sector to receive continuous training in 'gender mainstreaming' but in recent years only around 50 people have been trained and there is still no compulsory training in the subject within the Directorate-General for Development.\"]\n",
      "04/20 08:49:21 PM |\t  sacreBLEU : 7.064675\n",
      "04/20 08:49:21 PM |\t  BLEU : 0.058732\n",
      "04/20 08:49:21 PM |\t  test loss : 2.153083\n",
      "04/20 08:49:21 PM |\t  \n",
      "\n",
      "  ----------------epoch:1----------------\n",
      "04/20 08:49:37 PM |\t  step:100\t,avgloss:1.9432928042836708\n",
      "04/20 08:49:52 PM |\t  step:200\t,avgloss:2.0561815273761748\n",
      "04/20 08:50:07 PM |\t  step:300\t,avgloss:1.9988749718666077\n",
      "04/20 08:50:22 PM |\t  step:400\t,avgloss:1.9520105481147767\n",
      "04/20 08:50:36 PM |\t  step:500\t,avgloss:1.9894734635949134\n",
      "04/20 08:50:50 PM |\t  step:600\t,avgloss:2.1376180040836332\n",
      "04/20 08:51:04 PM |\t  step:700\t,avgloss:2.184474390745163\n",
      "04/20 08:51:16 PM |\t  x_decoded[:2]:['translate German to English: Betrifft: Einbeziehung der Gleichstellungspolitik in die gemeinschaftliche Beihilfepolitik Der Rat hat bereits 1995 Leitlinien für die Integrierung des Gleichstellungsaspekts in die gesamte gemeinschaftliche Beihilfepolitik ausgearbeitet.', 'translate German to English: Die Leitlinien verlangen, daß alle Mitarbeiter, die mit Entwicklungsfragen befaßt sind, kontinuierlich in der Gleichstellungsproblematik weitergebildet werden. In den letzten zwei Jahren haben aber nur rund 50 Personen an dieser Ausbildung teilgenommen, und in der GD Entwicklung gibt es noch immer keine obligatorische Schulung im Bereich Gleichstellung.']\n",
      "04/20 08:51:16 PM |\t  pred_decoded[:2]:['Concerning the integration of the equality policy in Community aid Policy The Council has already drafted 1995', 'The guidelines require that all staff who are involved in development will continue to be involved in the issue']\n",
      "04/20 08:51:16 PM |\t  label_decoded[:2]:[\"Subject: 'Mainstreaming' in EU aid policy In 1995 the Council drew up guidelines for integrating the equal opportunities dimension ('mainstreaming') into the full range of EU aid policy.\", \"The guidelines call for all staff working in the development sector to receive continuous training in 'gender mainstreaming' but in recent years only around 50 people have been trained and there is still no compulsory training in the subject within the Directorate-General for Development.\"]\n",
      "04/20 08:51:29 PM |\t  sacreBLEU : 7.683054\n",
      "04/20 08:51:29 PM |\t  BLEU : 0.068739\n",
      "04/20 08:51:29 PM |\t  test loss : 2.138798\n",
      "04/20 08:51:29 PM |\t  \n",
      "\n",
      "  ----------------epoch:2----------------\n",
      "04/20 08:51:45 PM |\t  step:100\t,avgloss:1.8160088965208223\n",
      "04/20 08:52:00 PM |\t  step:200\t,avgloss:1.9762738329172134\n",
      "04/20 08:52:13 PM |\t  step:300\t,avgloss:1.899899605512619\n",
      "04/20 08:52:27 PM |\t  step:400\t,avgloss:1.8430090945959092\n",
      "04/20 08:52:42 PM |\t  step:500\t,avgloss:1.8978803035616876\n",
      "04/20 08:52:56 PM |\t  step:600\t,avgloss:2.035578092336655\n",
      "04/20 08:53:10 PM |\t  step:700\t,avgloss:2.0685260355472566\n",
      "04/20 08:53:32 PM |\t  x_decoded[:2]:['translate German to English: Betrifft: Einbeziehung der Gleichstellungspolitik in die gemeinschaftliche Beihilfepolitik Der Rat hat bereits 1995 Leitlinien für die Integrierung des Gleichstellungsaspekts in die gesamte gemeinschaftliche Beihilfepolitik ausgearbeitet.', 'translate German to English: Die Leitlinien verlangen, daß alle Mitarbeiter, die mit Entwicklungsfragen befaßt sind, kontinuierlich in der Gleichstellungsproblematik weitergebildet werden. In den letzten zwei Jahren haben aber nur rund 50 Personen an dieser Ausbildung teilgenommen, und in der GD Entwicklung gibt es noch immer keine obligatorische Schulung im Bereich Gleichstellung.']\n",
      "04/20 08:53:32 PM |\t  pred_decoded[:2]:['Concerning the integration of the equality policy in Community aid Policy The Council has already developed 1995 guidelines', 'The guidelines require that all staff who are involved in development issues continue to be involved in the issue']\n",
      "04/20 08:53:32 PM |\t  label_decoded[:2]:[\"Subject: 'Mainstreaming' in EU aid policy In 1995 the Council drew up guidelines for integrating the equal opportunities dimension ('mainstreaming') into the full range of EU aid policy.\", \"The guidelines call for all staff working in the development sector to receive continuous training in 'gender mainstreaming' but in recent years only around 50 people have been trained and there is still no compulsory training in the subject within the Directorate-General for Development.\"]\n",
      "04/20 08:53:45 PM |\t  sacreBLEU : 7.619768\n",
      "04/20 08:53:45 PM |\t  BLEU : 0.067054\n",
      "04/20 08:53:45 PM |\t  test loss : 2.126845\n",
      "04/20 08:53:45 PM |\t  \n",
      "\n",
      "  ----------------epoch:3----------------\n",
      "04/20 08:54:02 PM |\t  step:100\t,avgloss:1.7336457241879832\n",
      "04/20 08:54:16 PM |\t  step:200\t,avgloss:1.8985449650883675\n",
      "04/20 08:54:30 PM |\t  step:300\t,avgloss:1.808324943780899\n",
      "04/20 08:54:44 PM |\t  step:400\t,avgloss:1.7563329857587815\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21016/2898451121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21016/584846173.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(_dataloader, model, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_y\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_x_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "my_test(valid_dataloader,model,-1)\n",
    "for epoch in range(10):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,model,optimizer )\n",
    "    my_test(valid_dataloader,model,epoch) \n",
    "\n",
    "torch.save(model,'./model/'+now+'model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
