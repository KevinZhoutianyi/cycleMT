{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "from parameter import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 500\n",
      "args.rep_iter 100\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 500, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=2,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=128,     help='max_length')\n",
    "    parser.add_argument('--num_beam', type=int,                     default=4,     help='num_beam')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=5e-6,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--G_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--G_grad_clip', type=float,                default=1,   help='grad_clip')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=5e-5,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--D_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--D_grad_clip', type=float,                default=1e-2,   help='grad_clip')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=0,   help='')\n",
    "    parser.add_argument('--lambda_GP', type=float,                  default=10,   help='WGANGP pentalty')\n",
    "    parser.add_argument('--DperG', type=int,                        default=2,    help='n_critc')\n",
    "    parser.add_argument('--GperD', type=int,                        default=2,    help='n_g')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.5,    help='labelsmoothing')\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--load_G', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=0,      help='whether valid before train')\n",
    "    parser.add_argument('--poolsize', type=int,                     default=1,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220531_003139-3ukxkp07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/3ukxkp07\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/cycleWMT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/3ukxkp07?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x216ba1e6b20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"cycleWMT\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/31 12:31:44 AM |\t  Namespace(D_A_model_name='Onlydrinkwater/T5-small-de-en', D_B_model_name='t5-small', D_gamma=1, D_grad_clip=0.01, D_lr=5e-05, D_pretrain_iter=0, D_weight_decay=0.001, DperG=2, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_gamma=1, G_grad_clip=1, G_lr=5e-06, G_weight_decay=0.001, GperD=2, batch_size=4, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=1, lambda_B=1, lambda_GP=10, lambda_identity=0.5, lambda_once=0, load_D=0, load_G=0, max_length=128, num_beam=2, num_workers=0, poolsize=1, rep_iter=100, smoothing=0.5, test_iter=500, train_D=1, train_G=1, train_num_points=500, valid_begin=1, valid_num_points=100)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/31 12:31:48 AM |\t  Gmodelsize:60.506624MB\n",
      "05/31 12:31:48 AM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/31 12:31:53 AM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 10.44it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16',language+'-en')#load_dataset(\"bible_para\", lang1=\"de\", lang2=\"en\")\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][-args.valid_num_points:]#TODO:\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/31 12:32:31 AM |\t  DB_a_: 0.162,  0.140,  0.157,  0.178,  \n",
      "05/31 12:32:31 AM |\t  DB_pred_dis: 0.168,  0.190,  0.193,  0.165,  \n",
      "05/31 12:32:31 AM |\t  DA_b: 0.155,  0.097,  0.017,  0.083,  \n",
      "05/31 12:32:31 AM |\t  DA_pred_dis: 0.157,  0.085,  0.038,  0.103,  \n",
      "05/31 12:32:31 AM |\t  GABloss:\t5.477481842041016\n",
      "05/31 12:32:31 AM |\t  GBAloss:\t9.78663444519043\n",
      "05/31 12:32:31 AM |\t  a_decoded[:2]:['Prestige Cruises, also based in Miami, operates under the Oceania and Regent brands, which together have eight cruise ships traveling to Scandinavia, Russia, the Mediterranean, North America, Asia, Africa and South America.', 'It posted revenues of $1.2 billion in 2013, up 6 percent from the year earlier.', 'The $29 billion cruise industry is expected to benefit in the coming years from the rise of the middle class in emerging economies such as China and India.', 'Companies are racing to position themselves as the cruise operators of choice for these new customers.']\n",
      "05/31 12:32:31 AM |\t  pred_b_decoded[:2]:['The Prestige cruises, which was also based in Miami, is owned by Oceania and Regent, which are the joint operators of eight cross-roads to Scandinavia, Russia, the Mediterranean, North America, Asia, Africa and South America.', 'Revenue for 2013 was reported to be USD 1.2 billion, an increase of 6% compared with last year.', 'In the next few years, the cross-border sector will be expected to be around USD 29 billion, and it will be expected to be in the next few years, due to the strengthening of the middle class in the swine countries such as China and India.', 'The companies are trying to position themselves as the best choice for these new customers in the cross-border operators.']\n",
      "05/31 12:32:31 AM |\t  b_decoded[:2]:['Prestige Cruises, ebenfalls in Miami angesiedelt, agiert unter den Markennamen Oceania und Regent, die gemeinsam acht Kreuzfahrschiffe auf Routen nach Skandinavien, Russland, dem Mittelmeer, Nordamerika, Asien, Afrika und Südamerika betreiben.', 'Es meldete Einnahmen für 2013 von 1,2 Milliarden $, ein Anstieg von 6 Prozent im Vergleich zum Vorjahr.', 'Die Kreuzfahrtbranche liegt insgesamt bei etwa 29 Milliarden $ und in den nächsten Jahren wird für sie aufgrund der Stärkung der Mittelklasse in Schwellenländern wie China und Indien erwartet.', 'Die Unternehmen versuchen sich für diese neuen Kunden als die beste Wahl bei den Kreuzfahrtanbietern zu positionieren.']\n",
      "05/31 12:32:31 AM |\t  pred_a_decoded[:2]:['Prestige Cruises, auch in Miami mit Sitz, hat acht Kreuzfahrtschiffe, die nach Skandinavien, Russland, dem Mittelmeerraum, Nordamerika, Asien, Afrika und Südamerika reisen.', 'Das Unternehmen erzielte einen Umsatz von 1,2 Milliarden Dollar im Jahr 2013 gegenüber dem Vorjahr.', 'Es wird erwartet, dass die Reiseindustrie in den kommenden Jahren von dem Aufstieg der Mittelschicht in Schwellenländern wie China und Indien profitieren wird.', 'Die Unternehmen setzen sich für diese neuen Kunden als die bevorzugten Kreuzfahrtbetreiber ein.']\n",
      "05/31 12:33:11 AM |\t  computing score...\n",
      "05/31 12:33:11 AM |\t  G_AB GAB sacreBLEU : 22.643928\n",
      "05/31 12:33:11 AM |\t  G_BA GBA sacreBLEU : 20.517663\n",
      "05/31 12:33:11 AM |\t  G_AB GAB test loss : 4.951000\n",
      "05/31 12:33:11 AM |\t  G_BA GBA test loss : 8.665833\n",
      "05/31 12:33:11 AM |\t  D_A DA test loss : -0.005828\n",
      "05/31 12:33:11 AM |\t  D_B DB test loss : 0.002552\n",
      "05/31 12:33:11 AM |\t  D_A DA test accuracy : 0.590000\n",
      "05/31 12:33:11 AM |\t  D_B DB test accuracy : 0.470000\n",
      "05/31 12:33:11 AM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "05/31 12:33:11 AM |\t  total iter:[0] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/31 12:34:59 AM |\t  {'GB_cycle_meter': 10.275145212809244, 'GA_cycle_meter': 10.264060974121094, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': 0.010993259474635125, 'DB_meter': -0.010540727525949478, 'DA_GP_meter': 0.02089175648987293, 'DB_GP_meter': 0.034557187855243685}\n",
      "05/31 12:34:59 AM |\t  19.2%\n",
      "05/31 12:36:43 AM |\t  {'GB_cycle_meter': 10.27252745628357, 'GA_cycle_meter': 10.25834846496582, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.01108243215829134, 'DB_meter': -0.011537465229630471, 'DA_GP_meter': 0.02313777044415474, 'DB_GP_meter': 0.029980682730674744}\n",
      "05/31 12:36:43 AM |\t  39.2%\n",
      "05/31 12:38:19 AM |\t  {'GB_cycle_meter': 10.27600149007944, 'GA_cycle_meter': 10.250519092266376, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.006514953132718802, 'DB_meter': -0.007311710417270661, 'DA_GP_meter': 0.01672152042388916, 'DB_GP_meter': 0.02164337269961834}\n",
      "05/31 12:38:19 AM |\t  59.199999999999996%\n",
      "05/31 12:40:02 AM |\t  {'GB_cycle_meter': 10.269968112309774, 'GA_cycle_meter': 10.252446254094442, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': 0.0005490651540458202, 'DB_meter': -0.007997234854847192, 'DA_GP_meter': 0.013565498106181621, 'DB_GP_meter': 0.021277662590146063}\n",
      "05/31 12:40:02 AM |\t  79.2%\n",
      "05/31 12:41:50 AM |\t  {'GB_cycle_meter': 10.264767793508677, 'GA_cycle_meter': 10.268937037541317, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0006941575184464454, 'DB_meter': 0.005040257908403873, 'DA_GP_meter': 0.010330923218280077, 'DB_GP_meter': 0.015541395107284188}\n",
      "05/31 12:41:50 AM |\t  99.2%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\main.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitCode/cycleMT/main.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(args\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitCode/cycleMT/main.ipynb#ch0000007?line=5'>6</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  ----------------epoch:\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m----------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/GitCode/cycleMT/main.ipynb#ch0000007?line=6'>7</a>\u001b[0m     my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
      "File \u001b[1;32mg:\\GitCode\\cycleMT\\train.py:60\u001b[0m, in \u001b[0;36mmy_train\u001b[1;34m(loader, model, total_iter, args, logging, valid_loader, tokenizer, wandb)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/train.py?line=56'>57</a>\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mG_BA,os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(wandb\u001b[39m.\u001b[39mrun\u001b[39m.\u001b[39mdir, \u001b[39m\"\u001b[39m\u001b[39mG_BA.pt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/train.py?line=57'>58</a>\u001b[0m wandb\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m./files/*.pt\u001b[39m\u001b[39m\"\u001b[39m, base_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./files\u001b[39m\u001b[39m\"\u001b[39m, policy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlive\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='file:///g%3A/GitCode/cycleMT/train.py?line=59'>60</a>\u001b[0m my_test(valid_loader,model,tokenizer,logging,wandb)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mg:\\GitCode\\cycleMT\\test.py:38\u001b[0m, in \u001b[0;36mmy_test\u001b[1;34m(loader, model, tokenizer, logging, wandb)\u001b[0m\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/test.py?line=33'>34</a>\u001b[0m b_attn \u001b[39m=\u001b[39m Variable(batch[\u001b[39m3\u001b[39m], requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/test.py?line=36'>37</a>\u001b[0m a_generate \u001b[39m=\u001b[39m GAB\u001b[39m.\u001b[39mtest_generate(a)[:,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m---> <a href='file:///g%3A/GitCode/cycleMT/test.py?line=37'>38</a>\u001b[0m b_generate  \u001b[39m=\u001b[39m GBA\u001b[39m.\u001b[39;49mtest_generate(b)[:,\u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/test.py?line=39'>40</a>\u001b[0m GAB_loss \u001b[39m=\u001b[39m GAB\u001b[39m.\u001b[39mforward(a,a_attn,b,b_attn)\u001b[39m.\u001b[39mloss\n\u001b[0;32m     <a href='file:///g%3A/GitCode/cycleMT/test.py?line=40'>41</a>\u001b[0m GBA_loss \u001b[39m=\u001b[39m GBA\u001b[39m.\u001b[39mforward(b,b_attn,a,a_attn)\u001b[39m.\u001b[39mloss\n",
      "File \u001b[1;32mg:\\GitCode\\cycleMT\\basic_model.py:172\u001b[0m, in \u001b[0;36mG.test_generate\u001b[1;34m(self, x, num_beams, max_length)\u001b[0m\n\u001b[0;32m    <a href='file:///g%3A/GitCode/cycleMT/basic_model.py?line=169'>170</a>\u001b[0m prefix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenzied_prefix\u001b[39m.\u001b[39mrepeat(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m)\u001b[39m#.cuda()\u001b[39;00m\n\u001b[0;32m    <a href='file:///g%3A/GitCode/cycleMT/basic_model.py?line=170'>171</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack((prefix,x))\n\u001b[1;32m--> <a href='file:///g%3A/GitCode/cycleMT/basic_model.py?line=171'>172</a>\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate( input_ids \u001b[39m=\u001b[39;49m x, num_beams \u001b[39m=\u001b[39;49m num_beams, early_stopping \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, max_length \u001b[39m=\u001b[39;49m max_length, length_penalty \u001b[39m=\u001b[39;49m\u001b[39m0.6\u001b[39;49m, repetition_penalty \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='file:///g%3A/GitCode/cycleMT/basic_model.py?line=172'>173</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output_ids\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\transformers\\generation_utils.py:1315\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1310'>1311</a>\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1311'>1312</a>\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1312'>1313</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1313'>1314</a>\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1314'>1315</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1315'>1316</a>\u001b[0m         input_ids,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1316'>1317</a>\u001b[0m         beam_scorer,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1317'>1318</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1318'>1319</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1319'>1320</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1320'>1321</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1321'>1322</a>\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1322'>1323</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1323'>1324</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1324'>1325</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1325'>1326</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1327'>1328</a>\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1328'>1329</a>\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1329'>1330</a>\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1330'>1331</a>\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k, top_p\u001b[39m=\u001b[39mtop_p, typical_p\u001b[39m=\u001b[39mtypical_p, temperature\u001b[39m=\u001b[39mtemperature, num_beams\u001b[39m=\u001b[39mnum_beams\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=1331'>1332</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\transformers\\generation_utils.py:2158\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2153'>2154</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2155'>2156</a>\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2157'>2158</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2158'>2159</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2159'>2160</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2160'>2161</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2161'>2162</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2162'>2163</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2164'>2165</a>\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/generation_utils.py?line=2165'>2166</a>\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\cycle\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1664\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1658'>1659</a>\u001b[0m     sequence_output \u001b[39m=\u001b[39m sequence_output\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1660'>1661</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mtie_word_embeddings:\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1661'>1662</a>\u001b[0m     \u001b[39m# Rescale output before projecting on vocab\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1662'>1663</a>\u001b[0m     \u001b[39m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1663'>1664</a>\u001b[0m     sequence_output \u001b[39m=\u001b[39m sequence_output \u001b[39m*\u001b[39;49m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_dim\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m0.5\u001b[39;49m)\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1665'>1666</a>\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(sequence_output)\n\u001b[0;32m   <a href='file:///c%3A/Users/kevin/miniconda3/envs/cycle/lib/site-packages/transformers/models/t5/modeling_t5.py?line=1667'>1668</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2a958cf2c5c0cd3cfa7593bb1f22c814db6e88adb2853f1b0eeb9f68d33d3cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cycle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
