{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "from parameter import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 500\n",
      "args.rep_iter 100\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 300, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 1000, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=4,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=128,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=5e-6,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--G_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--G_grad_clip', type=float,                default=1,   help='grad_clip')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=5e-5,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--D_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--D_grad_clip', type=float,                default=1e-2,   help='grad_clip')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=0,   help='')\n",
    "    parser.add_argument('--lambda_GP', type=float,                  default=10,   help='WGANGP pentalty')\n",
    "    parser.add_argument('--DperG', type=int,                        default=2,    help='n_critc')\n",
    "    parser.add_argument('--GperD', type=int,                        default=2,    help='n_g')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.5,    help='labelsmoothing')\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--load_G', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=0,      help='whether valid before train')\n",
    "    parser.add_argument('--poolsize', type=int,                     default=1,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220529_164755-1337mki1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/1337mki1\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/cycleWMT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/1337mki1?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1da5ee6fb80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"cycleWMT\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/29 04:48:02 PM |\t  Namespace(D_A_model_name='Onlydrinkwater/T5-small-de-en', D_B_model_name='t5-small', D_gamma=1, D_grad_clip=0.01, D_lr=5e-05, D_pretrain_iter=0, D_weight_decay=0.001, DperG=2, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_gamma=1, G_grad_clip=1, G_lr=5e-06, G_weight_decay=0.001, GperD=2, batch_size=4, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=1, lambda_B=1, lambda_GP=10, lambda_identity=0.5, lambda_once=0, load_D=0, load_G=0, max_length=128, num_workers=0, poolsize=1, rep_iter=100, smoothing=0.5, test_iter=500, train_D=1, train_G=1, train_num_points=1000, valid_begin=1, valid_num_points=300)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_54836/3794013030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mGBApretrained\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGBAmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mDApretrained\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDAmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mDBpretrained\u001b[0m  \u001b[1;33m=\u001b[0m  \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDBmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m         raise ValueError(\n\u001b[0;32m    448\u001b[0m             \u001b[1;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mno_init_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_enable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fast_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1843\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfrom_pt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1474\u001b[0m         \u001b[0mencoder_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m         \u001b[0mencoder_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT5Stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mdecoder_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, embed_tokens)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         self.block = nn.ModuleList(\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mT5Block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT5LayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         self.block = nn.ModuleList(\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0mT5Block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_layer_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT5LayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT5LayerSelfAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT5LayerCrossAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelfAttention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT5Attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhas_relative_attention_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT5LayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;31m# Mesh TensorFlow initialization to avoid scaling before softmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[1;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.410496"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "M  =  AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "count_parameters_in_MB(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=58101, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/22 03:39:35 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16',language+'-en')#load_dataset(\"bible_para\", lang1=\"de\", lang2=\"en\")\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][-args.valid_num_points:]#TODO:\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/22 03:40:19 PM |\t  DB_a_: -0.19,  -0.15,  -0.15,  -0.10,  \n",
      "05/22 03:40:19 PM |\t  DB_pred_dis: -0.17,  -0.11,  -0.17,  -0.09,  \n",
      "05/22 03:40:19 PM |\t  DA_b: 0.042,  0.066,  0.063,  0.066,  \n",
      "05/22 03:40:19 PM |\t  DA_pred_dis: 0.047,  0.050,  0.102,  0.068,  \n",
      "05/22 03:40:19 PM |\t  GABloss:\t4.895842552185059\n",
      "05/22 03:40:19 PM |\t  GBAloss:\t10.294256210327148\n",
      "05/22 03:40:19 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 03:40:19 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', '.', \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/22 03:40:19 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 03:40:19 PM |\t  pred_a_decoded[:2]:['Er lernte diese Lektion auf hartem Wege.', 'Während der letzten vier Wochen wurde er in der College Buchhandlung vollen Preis bezahlen.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 hat in den USA weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 03:42:11 PM |\t  computing score...\n",
      "05/22 03:42:11 PM |\t  G_AB GAB sacreBLEU : 24.361509\n",
      "05/22 03:42:11 PM |\t  G_BA GBA sacreBLEU : 20.984371\n",
      "05/22 03:42:11 PM |\t  G_AB GAB test loss : 5.302500\n",
      "05/22 03:42:11 PM |\t  G_BA GBA test loss : 8.912396\n",
      "05/22 03:42:11 PM |\t  D_A DA test loss : 0.003993\n",
      "05/22 03:42:11 PM |\t  D_B DB test loss : -0.004441\n",
      "05/22 03:42:11 PM |\t  D_A DA test accuracy : 0.450000\n",
      "05/22 03:42:11 PM |\t  D_B DB test accuracy : 0.530000\n",
      "05/22 03:42:11 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "05/22 03:42:11 PM |\t  total iter:[0] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/22 03:43:47 PM |\t  {'GB_cycle_meter': 10.304630994796753, 'GA_cycle_meter': 10.26951821645101, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0026073549315333367, 'DB_meter': 0.01326206848025322, 'DA_GP_meter': 0.021941961012780665, 'DB_GP_meter': 0.04919838637113571}\n",
      "05/22 03:43:47 PM |\t  9.6%\n",
      "05/22 03:45:26 PM |\t  {'GB_cycle_meter': 10.291357596715292, 'GA_cycle_meter': 10.261818408966064, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0031345214694738386, 'DB_meter': 0.005975795090198517, 'DA_GP_meter': 0.015823833979666233, 'DB_GP_meter': 0.029237568192183972}\n",
      "05/22 03:45:26 PM |\t  19.6%\n",
      "05/22 03:47:08 PM |\t  {'GB_cycle_meter': 10.290476432213417, 'GA_cycle_meter': 10.254184942979078, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.008250930160284043, 'DB_meter': 0.0009337064251303673, 'DA_GP_meter': 0.010586442556232215, 'DB_GP_meter': 0.04803311407566071}\n",
      "05/22 03:47:08 PM |\t  29.599999999999998%\n",
      "05/22 03:48:49 PM |\t  {'GB_cycle_meter': 10.305078903834024, 'GA_cycle_meter': 10.279488245646158, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': 0.009115762300789356, 'DB_meter': 0.0036602082662284376, 'DA_GP_meter': 0.010832327902317047, 'DB_GP_meter': 0.015625294814817607}\n",
      "05/22 03:48:49 PM |\t  39.6%\n",
      "05/22 03:50:26 PM |\t  {'GB_cycle_meter': 10.259273969210112, 'GA_cycle_meter': 10.234170253460224, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.026145465970039368, 'DB_meter': 0.0005855629406869412, 'DA_GP_meter': 0.00831262143328786, 'DB_GP_meter': 0.005307516924804076}\n",
      "05/22 03:50:26 PM |\t  49.6%\n",
      "05/22 03:50:34 PM |\t  DB_a_: -0.04,  -0.04,  -0.05,  -0.03,  \n",
      "05/22 03:50:34 PM |\t  DB_pred_dis: -0.04,  -0.03,  -0.04,  -0.03,  \n",
      "05/22 03:50:34 PM |\t  DA_b: 0.032,  0.056,  0.068,  0.092,  \n",
      "05/22 03:50:34 PM |\t  DA_pred_dis: 0.026,  0.056,  0.077,  0.112,  \n",
      "05/22 03:50:34 PM |\t  GABloss:\t4.892641544342041\n",
      "05/22 03:50:34 PM |\t  GBAloss:\t10.5905179977417\n",
      "05/22 03:50:34 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 03:50:34 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', '.', \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/22 03:50:34 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 03:50:34 PM |\t  pred_a_decoded[:2]:['Er lernte diese Lektion auf hartem Wege.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 hat in den USA weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 03:52:27 PM |\t  computing score...\n",
      "05/22 03:52:27 PM |\t  G_AB GAB sacreBLEU : 24.833895\n",
      "05/22 03:52:27 PM |\t  G_BA GBA sacreBLEU : 21.182230\n",
      "05/22 03:52:27 PM |\t  G_AB GAB test loss : 5.294416\n",
      "05/22 03:52:27 PM |\t  G_BA GBA test loss : 9.236127\n",
      "05/22 03:52:27 PM |\t  D_A DA test loss : -0.004838\n",
      "05/22 03:52:27 PM |\t  D_B DB test loss : -0.000159\n",
      "05/22 03:52:27 PM |\t  D_A DA test accuracy : 0.633333\n",
      "05/22 03:52:27 PM |\t  D_B DB test accuracy : 0.496667\n",
      "05/22 03:54:01 PM |\t  {'GB_cycle_meter': 10.244509061177572, 'GA_cycle_meter': 10.23281995455424, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.002172022182494402, 'DB_meter': -0.00010561792179942131, 'DA_GP_meter': 0.0025652777031064033, 'DB_GP_meter': 0.0005447121587349102}\n",
      "05/22 03:54:01 PM |\t  59.599999999999994%\n",
      "05/22 03:55:31 PM |\t  {'GB_cycle_meter': 10.225914808420034, 'GA_cycle_meter': 10.17491942185622, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.002632851656526327, 'DB_meter': -0.0006336827203631401, 'DA_GP_meter': 0.002539347419515252, 'DB_GP_meter': 0.00045308404456591235}\n",
      "05/22 03:55:31 PM |\t  69.6%\n",
      "05/22 03:57:01 PM |\t  {'GB_cycle_meter': 10.170342365900675, 'GA_cycle_meter': 10.17322293917338, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0022803968377411365, 'DB_meter': 0.0001726004108786583, 'DA_GP_meter': 0.002282956833951175, 'DB_GP_meter': 0.0002462073092465289}\n",
      "05/22 03:57:01 PM |\t  79.60000000000001%\n",
      "05/22 03:58:25 PM |\t  {'GB_cycle_meter': 10.242345516498272, 'GA_cycle_meter': 10.183181469257061, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.006599015574902296, 'DB_meter': -0.0019594576582312585, 'DA_GP_meter': 0.002254999331198633, 'DB_GP_meter': 0.0002890571502211969}\n",
      "05/22 03:58:25 PM |\t  89.60000000000001%\n",
      "05/22 04:00:01 PM |\t  {'GB_cycle_meter': 10.260769446690878, 'GA_cycle_meter': 10.196444670359293, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0023090921528637408, 'DB_meter': -0.001045930963009596, 'DA_GP_meter': 0.0023680318193510176, 'DB_GP_meter': 0.000430923891835846}\n",
      "05/22 04:00:01 PM |\t  99.6%\n",
      "05/22 04:00:09 PM |\t  DB_a_: -0.05,  -0.04,  -0.05,  -0.04,  \n",
      "05/22 04:00:09 PM |\t  DB_pred_dis: -0.06,  -0.04,  -0.04,  -0.03,  \n",
      "05/22 04:00:09 PM |\t  DA_b: 0.014,  0.050,  0.067,  0.080,  \n",
      "05/22 04:00:09 PM |\t  DA_pred_dis: 0.021,  0.042,  0.069,  0.094,  \n",
      "05/22 04:00:09 PM |\t  GABloss:\t4.899685382843018\n",
      "05/22 04:00:09 PM |\t  GBAloss:\t11.035550117492676\n",
      "05/22 04:00:09 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:00:09 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/22 04:00:09 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:00:09 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 04:02:01 PM |\t  computing score...\n",
      "05/22 04:02:01 PM |\t  G_AB GAB sacreBLEU : 25.161804\n",
      "05/22 04:02:01 PM |\t  G_BA GBA sacreBLEU : 21.836660\n",
      "05/22 04:02:01 PM |\t  G_AB GAB test loss : 5.297862\n",
      "05/22 04:02:01 PM |\t  G_BA GBA test loss : 9.736232\n",
      "05/22 04:02:01 PM |\t  D_A DA test loss : -0.010747\n",
      "05/22 04:02:01 PM |\t  D_B DB test loss : -0.001351\n",
      "05/22 04:02:01 PM |\t  D_A DA test accuracy : 0.693333\n",
      "05/22 04:02:01 PM |\t  D_B DB test accuracy : 0.563333\n",
      "05/22 04:02:01 PM |\t  \n",
      "\n",
      "  ----------------epoch:1----------------\n",
      "05/22 04:02:01 PM |\t  total iter:[1000] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/22 04:03:37 PM |\t  {'GB_cycle_meter': 10.246752262115479, 'GA_cycle_meter': 10.231356461842855, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.019899206310510634, 'DB_meter': -0.0034878769516944884, 'DA_GP_meter': 0.007354742623865604, 'DB_GP_meter': 0.0011417239753063768}\n",
      "05/22 04:03:37 PM |\t  9.6%\n",
      "05/22 04:05:11 PM |\t  {'GB_cycle_meter': 10.285427252451578, 'GA_cycle_meter': 10.261791229248047, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.017778093703091146, 'DB_meter': -0.004880922809243202, 'DA_GP_meter': 0.007119279187172652, 'DB_GP_meter': 0.001185602443292737}\n",
      "05/22 04:05:11 PM |\t  19.6%\n",
      "05/22 04:06:50 PM |\t  {'GB_cycle_meter': 10.266020334683931, 'GA_cycle_meter': 10.258879294762245, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.016015000753104688, 'DB_meter': -0.0012207746133208275, 'DA_GP_meter': 0.006898291148245334, 'DB_GP_meter': 0.0003417901034117676}\n",
      "05/22 04:06:50 PM |\t  29.599999999999998%\n",
      "05/22 04:08:29 PM |\t  {'GB_cycle_meter': 10.222127993901571, 'GA_cycle_meter': 10.252625385920206, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.008407470732927323, 'DB_meter': -0.002367604412138462, 'DA_GP_meter': 0.006175555307418108, 'DB_GP_meter': 0.00030739822512259706}\n",
      "05/22 04:08:29 PM |\t  39.6%\n",
      "05/22 04:10:09 PM |\t  {'GB_cycle_meter': 10.273724115811861, 'GA_cycle_meter': 10.26657955463116, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.01667450003325939, 'DB_meter': 0.00017784930765628814, 'DA_GP_meter': 0.00682180481031537, 'DB_GP_meter': 0.00021146573562873526}\n",
      "05/22 04:10:09 PM |\t  49.6%\n",
      "05/22 04:10:17 PM |\t  DB_a_: -0.06,  -0.06,  -0.06,  -0.06,  \n",
      "05/22 04:10:17 PM |\t  DB_pred_dis: -0.07,  -0.06,  -0.06,  -0.06,  \n",
      "05/22 04:10:17 PM |\t  DA_b: 0.020,  0.074,  0.083,  0.113,  \n",
      "05/22 04:10:17 PM |\t  DA_pred_dis: 0.034,  0.048,  0.079,  0.120,  \n",
      "05/22 04:10:17 PM |\t  GABloss:\t4.891787052154541\n",
      "05/22 04:10:17 PM |\t  GBAloss:\t11.39612102508545\n",
      "05/22 04:10:17 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:10:17 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/22 04:10:17 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:10:17 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 04:12:09 PM |\t  computing score...\n",
      "05/22 04:12:09 PM |\t  G_AB GAB sacreBLEU : 25.325149\n",
      "05/22 04:12:09 PM |\t  G_BA GBA sacreBLEU : 21.564853\n",
      "05/22 04:12:09 PM |\t  G_AB GAB test loss : 5.273455\n",
      "05/22 04:12:09 PM |\t  G_BA GBA test loss : 10.132058\n",
      "05/22 04:12:09 PM |\t  D_A DA test loss : -0.015067\n",
      "05/22 04:12:09 PM |\t  D_B DB test loss : -0.000377\n",
      "05/22 04:12:09 PM |\t  D_A DA test accuracy : 0.706667\n",
      "05/22 04:12:09 PM |\t  D_B DB test accuracy : 0.600000\n",
      "05/22 04:13:39 PM |\t  {'GB_cycle_meter': 10.254813273747763, 'GA_cycle_meter': 10.169778823852539, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.021732121333479883, 'DB_meter': -0.00026435375213623046, 'DA_GP_meter': 0.0031661138962954284, 'DB_GP_meter': 1.942066948686261e-05}\n",
      "05/22 04:13:39 PM |\t  59.599999999999994%\n",
      "05/22 04:15:22 PM |\t  {'GB_cycle_meter': 10.249144920935997, 'GA_cycle_meter': 10.146370007441593, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.017603595331311225, 'DB_meter': -0.0007752463221549988, 'DA_GP_meter': 0.0038656003307551146, 'DB_GP_meter': 2.0087449811398984e-05}\n",
      "05/22 04:15:22 PM |\t  69.6%\n",
      "05/22 04:16:54 PM |\t  {'GB_cycle_meter': 10.228573481241861, 'GA_cycle_meter': 10.14157478014628, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.02951418615877628, 'DB_meter': -0.00048036955296993256, 'DA_GP_meter': 0.004110077330842614, 'DB_GP_meter': 5.438942709588446e-05}\n",
      "05/22 04:16:54 PM |\t  79.60000000000001%\n",
      "05/22 04:18:30 PM |\t  {'GB_cycle_meter': 10.228490756108211, 'GA_cycle_meter': 10.223003827608549, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.042617235779762265, 'DB_meter': -0.0019159692898392678, 'DA_GP_meter': 0.006325891967862845, 'DB_GP_meter': 0.0002052452137286309}\n",
      "05/22 04:18:30 PM |\t  89.60000000000001%\n",
      "05/22 04:19:57 PM |\t  {'GB_cycle_meter': 10.238898754119873, 'GA_cycle_meter': 10.130008141199747, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.039410682842135426, 'DB_meter': -0.0028746411949396133, 'DA_GP_meter': 0.009323329664766788, 'DB_GP_meter': 0.0005066322127822787}\n",
      "05/22 04:19:57 PM |\t  99.6%\n",
      "05/22 04:20:05 PM |\t  DB_a_: -0.06,  -0.05,  -0.05,  -0.04,  \n",
      "05/22 04:20:05 PM |\t  DB_pred_dis: -0.06,  -0.05,  -0.05,  -0.04,  \n",
      "05/22 04:20:05 PM |\t  DA_b: 0.052,  0.080,  0.160,  0.225,  \n",
      "05/22 04:20:05 PM |\t  DA_pred_dis: 0.071,  0.091,  0.113,  0.223,  \n",
      "05/22 04:20:05 PM |\t  GABloss:\t4.888986110687256\n",
      "05/22 04:20:05 PM |\t  GBAloss:\t11.73132610321045\n",
      "05/22 04:20:05 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:20:05 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/22 04:20:05 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:20:05 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For lediglich 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 04:21:55 PM |\t  computing score...\n",
      "05/22 04:21:56 PM |\t  G_AB GAB sacreBLEU : 25.392630\n",
      "05/22 04:21:56 PM |\t  G_BA GBA sacreBLEU : 21.792467\n",
      "05/22 04:21:56 PM |\t  G_AB GAB test loss : 5.269201\n",
      "05/22 04:21:56 PM |\t  G_BA GBA test loss : 10.452422\n",
      "05/22 04:21:56 PM |\t  D_A DA test loss : -0.039011\n",
      "05/22 04:21:56 PM |\t  D_B DB test loss : -0.002568\n",
      "05/22 04:21:56 PM |\t  D_A DA test accuracy : 0.743333\n",
      "05/22 04:21:56 PM |\t  D_B DB test accuracy : 0.556667\n",
      "05/22 04:21:56 PM |\t  \n",
      "\n",
      "  ----------------epoch:2----------------\n",
      "05/22 04:21:56 PM |\t  total iter:[2000] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/22 04:23:35 PM |\t  {'GB_cycle_meter': 10.301235357920328, 'GA_cycle_meter': 10.257119019826254, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.06816706240177155, 'DB_meter': -0.004280731063336134, 'DA_GP_meter': 0.02019945465028286, 'DB_GP_meter': 0.0018002545816125349}\n",
      "05/22 04:23:35 PM |\t  9.6%\n",
      "05/22 04:25:15 PM |\t  {'GB_cycle_meter': 10.284462372461954, 'GA_cycle_meter': 10.282727797826132, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.035432382673025134, 'DB_meter': -0.0032637666538357733, 'DA_GP_meter': 0.01794109608978033, 'DB_GP_meter': 0.002159384359838441}\n",
      "05/22 04:25:15 PM |\t  19.6%\n",
      "05/22 04:26:52 PM |\t  {'GB_cycle_meter': 10.296984892625074, 'GA_cycle_meter': 10.265112216656025, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.04652266781777144, 'DB_meter': 0.0018259635008871554, 'DA_GP_meter': 0.019616867154836654, 'DB_GP_meter': 0.0007001248252345249}\n",
      "05/22 04:26:52 PM |\t  29.599999999999998%\n",
      "05/22 04:28:32 PM |\t  {'GB_cycle_meter': 10.272126913070679, 'GA_cycle_meter': 10.272495667139689, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.06145776446908712, 'DB_meter': -0.004724532216787338, 'DA_GP_meter': 0.020351445451378822, 'DB_GP_meter': 0.0006089486292330548}\n",
      "05/22 04:28:32 PM |\t  39.6%\n",
      "05/22 04:30:05 PM |\t  {'GB_cycle_meter': 10.266758038447453, 'GA_cycle_meter': 10.204657921424278, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.056699124425649644, 'DB_meter': 0.00248692262917757, 'DA_GP_meter': 0.019595791585743427, 'DB_GP_meter': 0.0007081244236906059}\n",
      "05/22 04:30:05 PM |\t  49.6%\n",
      "05/22 04:30:13 PM |\t  DB_a_: -0.07,  -0.06,  -0.06,  -0.06,  \n",
      "05/22 04:30:13 PM |\t  DB_pred_dis: -0.07,  -0.06,  -0.07,  -0.06,  \n",
      "05/22 04:30:13 PM |\t  DA_b: 0.019,  0.028,  0.179,  0.261,  \n",
      "05/22 04:30:13 PM |\t  DA_pred_dis: 0.039,  0.100,  0.090,  0.248,  \n",
      "05/22 04:30:13 PM |\t  GABloss:\t4.8812384605407715\n",
      "05/22 04:30:13 PM |\t  GBAloss:\t12.136321067810059\n",
      "05/22 04:30:13 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:30:13 PM |\t  pred_b_decoded[:2]:['This lesson was learned on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million of his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million of his 70 million budget.\"]\n",
      "05/22 04:30:13 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:30:13 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For lediglich 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 04:32:05 PM |\t  computing score...\n",
      "05/22 04:32:05 PM |\t  G_AB GAB sacreBLEU : 25.613618\n",
      "05/22 04:32:05 PM |\t  G_BA GBA sacreBLEU : 21.890695\n",
      "05/22 04:32:05 PM |\t  G_AB GAB test loss : 5.255535\n",
      "05/22 04:32:05 PM |\t  G_BA GBA test loss : 10.854849\n",
      "05/22 04:32:05 PM |\t  D_A DA test loss : -0.048025\n",
      "05/22 04:32:05 PM |\t  D_B DB test loss : -0.001093\n",
      "05/22 04:32:05 PM |\t  D_A DA test accuracy : 0.750000\n",
      "05/22 04:32:05 PM |\t  D_B DB test accuracy : 0.636667\n",
      "05/22 04:33:40 PM |\t  {'GB_cycle_meter': 10.200405677159628, 'GA_cycle_meter': 10.153822422027588, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.103522769510746, 'DB_meter': -0.001304684989154339, 'DA_GP_meter': 0.014687916804105043, 'DB_GP_meter': 0.00020633872736652847}\n",
      "05/22 04:33:40 PM |\t  59.599999999999994%\n",
      "05/22 04:35:08 PM |\t  {'GB_cycle_meter': 10.239090039179874, 'GA_cycle_meter': 10.1426970408513, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.14494628921151162, 'DB_meter': -0.0033089812472462655, 'DA_GP_meter': 0.02385682888329029, 'DB_GP_meter': 0.00034717296541202813}\n",
      "05/22 04:35:08 PM |\t  69.6%\n",
      "05/22 04:36:35 PM |\t  {'GB_cycle_meter': 10.155965805053711, 'GA_cycle_meter': 10.158311367034912, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.18688430458307267, 'DB_meter': -0.007018949016928673, 'DA_GP_meter': 0.032953800298273564, 'DB_GP_meter': 0.0005786019866354763}\n",
      "05/22 04:36:35 PM |\t  79.60000000000001%\n",
      "05/22 04:38:09 PM |\t  {'GB_cycle_meter': 10.229452059819149, 'GA_cycle_meter': 10.17878825847919, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.24448289662599565, 'DB_meter': -0.009394377879798412, 'DA_GP_meter': 0.041995874047279357, 'DB_GP_meter': 0.0012483633332885803}\n",
      "05/22 04:38:09 PM |\t  89.60000000000001%\n",
      "05/22 04:39:51 PM |\t  {'GB_cycle_meter': 10.251208225886026, 'GA_cycle_meter': 10.227474689483643, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.24537079632282258, 'DB_meter': -0.01144102893769741, 'DA_GP_meter': 0.044080439284443856, 'DB_GP_meter': 0.0009947821998503058}\n",
      "05/22 04:39:51 PM |\t  99.6%\n",
      "05/22 04:39:59 PM |\t  DB_a_: -0.06,  -0.01,  -0.03,  -0.02,  \n",
      "05/22 04:39:59 PM |\t  DB_pred_dis: -0.04,  -0.03,  -0.03,  -0.00,  \n",
      "05/22 04:39:59 PM |\t  DA_b: 0.000,  -0.39,  0.400,  0.541,  \n",
      "05/22 04:39:59 PM |\t  DA_pred_dis: 0.119,  0.208,  0.260,  0.463,  \n",
      "05/22 04:39:59 PM |\t  GABloss:\t4.88826847076416\n",
      "05/22 04:39:59 PM |\t  GBAloss:\t12.40693473815918\n",
      "05/22 04:39:59 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:39:59 PM |\t  pred_b_decoded[:2]:['This lesson was learned on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million of his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million of his 70 million budget.\"]\n",
      "05/22 04:39:59 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:39:59 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For lediglich 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/22 04:41:50 PM |\t  computing score...\n",
      "05/22 04:41:50 PM |\t  G_AB GAB sacreBLEU : 25.588328\n",
      "05/22 04:41:50 PM |\t  G_BA GBA sacreBLEU : 22.014417\n",
      "05/22 04:41:50 PM |\t  G_AB GAB test loss : 5.258566\n",
      "05/22 04:41:50 PM |\t  G_BA GBA test loss : 11.148033\n",
      "05/22 04:41:50 PM |\t  D_A DA test loss : -0.107764\n",
      "05/22 04:41:50 PM |\t  D_B DB test loss : -0.011075\n",
      "05/22 04:41:50 PM |\t  D_A DA test accuracy : 0.736667\n",
      "05/22 04:41:50 PM |\t  D_B DB test accuracy : 0.646667\n",
      "05/22 04:41:50 PM |\t  \n",
      "\n",
      "  ----------------epoch:3----------------\n",
      "05/22 04:41:50 PM |\t  total iter:[3000] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/22 04:43:31 PM |\t  {'GB_cycle_meter': 10.282365640004477, 'GA_cycle_meter': 10.198503732681274, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.1969638781249523, 'DB_meter': -0.0085204310528934, 'DA_GP_meter': 0.07481163293123246, 'DB_GP_meter': 0.004892426480073482}\n",
      "05/22 04:43:31 PM |\t  9.6%\n",
      "05/22 04:45:09 PM |\t  {'GB_cycle_meter': 10.252435525258383, 'GA_cycle_meter': 10.222668329874674, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.20700875386595727, 'DB_meter': -0.010493003427982331, 'DA_GP_meter': 0.09019112914800644, 'DB_GP_meter': 0.001386563170235604}\n",
      "05/22 04:45:09 PM |\t  19.6%\n",
      "05/22 04:46:49 PM |\t  {'GB_cycle_meter': 10.293961451603817, 'GA_cycle_meter': 10.193401116591234, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.2014793075621128, 'DB_meter': -0.004994189590215683, 'DA_GP_meter': 0.08383837163448334, 'DB_GP_meter': 0.0012285347521537914}\n",
      "05/22 04:46:49 PM |\t  29.599999999999998%\n",
      "05/22 04:48:35 PM |\t  {'GB_cycle_meter': 10.276021321614584, 'GA_cycle_meter': 10.261037349700928, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.2204161813855171, 'DB_meter': -0.002296190857887268, 'DA_GP_meter': 0.0735197664797306, 'DB_GP_meter': 0.0009324374387506396}\n",
      "05/22 04:48:35 PM |\t  39.6%\n",
      "05/22 04:50:18 PM |\t  {'GB_cycle_meter': 10.260733237633339, 'GA_cycle_meter': 10.26972557948186, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.15726716071367264, 'DB_meter': -0.0031124741211533548, 'DA_GP_meter': 0.14997860580682754, 'DB_GP_meter': 0.0003742558817612007}\n",
      "05/22 04:50:18 PM |\t  49.6%\n",
      "05/22 04:50:27 PM |\t  DB_a_: -0.08,  -0.07,  -0.07,  -0.06,  \n",
      "05/22 04:50:27 PM |\t  DB_pred_dis: -0.07,  -0.07,  -0.07,  -0.06,  \n",
      "05/22 04:50:27 PM |\t  DA_b: -0.12,  -0.53,  0.264,  0.447,  \n",
      "05/22 04:50:27 PM |\t  DA_pred_dis: -0.02,  0.058,  0.102,  0.333,  \n",
      "05/22 04:50:27 PM |\t  GABloss:\t4.8847551345825195\n",
      "05/22 04:50:27 PM |\t  GBAloss:\t12.8886079788208\n",
      "05/22 04:50:27 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/22 04:50:27 PM |\t  pred_b_decoded[:2]:['This lesson was learned on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million of his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million of his 70 million budget.\"]\n",
      "05/22 04:50:27 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/22 04:50:27 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf harte Weise gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For lediglich 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n"
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
