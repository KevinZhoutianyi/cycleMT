{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "from parameter import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 500\n",
      "args.rep_iter 100\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 500, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=4,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=128,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=5e-5,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--G_gamma', type=float,                    default=0.9,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--G_grad_clip', type=float,                default=1,   help='grad_clip')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=5e-5,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--D_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--D_grad_clip', type=float,                default=1e-2,   help='grad_clip')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=1,   help='')\n",
    "    parser.add_argument('--lambda_GP', type=float,                  default=0.1,   help='WGANGP pentalty')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.5,    help='labelsmoothing')\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--load_G', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=0,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=100,      help='whether valid before train')\n",
    "    parser.add_argument('--poolsize', type=int,                     default=1,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220509_195631-pwvfvvlt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/pwvfvvlt\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/pwvfvvlt?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15f910d2af0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"CYCLEGAN\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 07:56:38 PM |\t  Namespace(D_A_model_name='t5-small', D_B_model_name='Onlydrinkwater/T5-small-de-en', D_gamma=1, D_grad_clip=0.01, D_lr=5e-05, D_pretrain_iter=100, D_weight_decay=0.001, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_gamma=0.9, G_grad_clip=1, G_lr=5e-05, G_weight_decay=0.001, batch_size=4, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=0, lambda_B=0, lambda_GP=0.1, lambda_identity=0.5, lambda_once=1, load_D=0, load_G=0, max_length=128, num_workers=0, poolsize=1, rep_iter=100, smoothing=0.5, test_iter=500, train_D=1, train_G=1, train_num_points=500, valid_begin=0, valid_num_points=100)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 07:56:43 PM |\t  Gmodelsize:60.506624MB\n",
      "05/09 07:56:43 PM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 07:56:46 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16',language+'-en')\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][:args.valid_num_points]#TODO:\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 07:57:16 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "05/09 07:57:16 PM |\t  total iter:[0] \t G_lr:5e-05 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/09 07:58:48 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06375954300165176, 'GBA_once_meter': -0.06282003223896027, 'DA_meter': 8.093127980828285e-05, 'DB_meter': 0.0009445646218955517, 'DA_GP_meter': 0.12486051961779594, 'DB_GP_meter': 0.08115321204066277}\n",
      "05/09 07:58:48 PM |\t  19.2%\n",
      "05/09 08:00:21 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.05600299030542374, 'GBA_once_meter': -0.06252969726920128, 'DA_meter': 0.008210825566202402, 'DB_meter': 0.004368491321802139, 'DA_GP_meter': 0.08417605295777321, 'DB_GP_meter': 0.07958656281232834}\n",
      "05/09 08:00:21 PM |\t  39.2%\n",
      "05/09 08:01:50 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06322695881128311, 'GBA_once_meter': -0.056938153356313706, 'DA_meter': -0.00234952449798584, 'DB_meter': -0.002657540962100029, 'DA_GP_meter': 0.07503188341856003, 'DB_GP_meter': 0.15948908999562264}\n",
      "05/09 08:01:50 PM |\t  59.199999999999996%\n",
      "05/09 08:03:25 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06313281312584877, 'GBA_once_meter': -0.05555188067257404, 'DA_meter': 0.00153978668153286, 'DB_meter': -0.006294173747301101, 'DA_GP_meter': 0.08025535717606544, 'DB_GP_meter': 0.07945131942629814}\n",
      "05/09 08:03:25 PM |\t  79.2%\n",
      "05/09 08:04:58 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06775729298591614, 'GBA_once_meter': -0.05458521299064159, 'DA_meter': -0.0004429242387413979, 'DB_meter': -0.001962537430226803, 'DA_GP_meter': 0.0785167357325554, 'DB_GP_meter': 0.08939322859048843}\n",
      "05/09 08:04:58 PM |\t  99.2%\n",
      "05/09 08:05:05 PM |\t  DB_a_: 0.046,  0.060,  0.078,  0.075,  \n",
      "05/09 08:05:05 PM |\t  DB_pred_dis: 0.024,  0.053,  0.083,  0.075,  \n",
      "05/09 08:05:05 PM |\t  DA_b: -0.07,  -0.02,  -0.09,  -0.08,  \n",
      "05/09 08:05:05 PM |\t  DA_pred_dis: -0.06,  -0.04,  -0.09,  -0.07,  \n",
      "05/09 08:05:05 PM |\t  GABloss:\t3.8784537315368652\n",
      "05/09 08:05:05 PM |\t  GBAloss:\t10.99131965637207\n",
      "05/09 08:05:05 PM |\t  a_decoded[:2]:['India and Japan prime ministers meet in Tokyo', \"India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\", 'Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.', 'High on the agenda are plans for greater nuclear co-operation.']\n",
      "05/09 08:05:05 PM |\t  pred_b_decoded[:2]:['The Prime Ministers of India and Japan met in Tokyo.', 'Prime Minister Narendra Modi, who is the new Prime Minister of India, will visit Toko in May to discuss economic and security relations with his Japanese counterpart, Shinzo Abe.', 'Mr Modi is on a five-day trip to Japan to strengthen economic relations with the third largest economic nation in the world.', 'More nuclear cooperation is on the agenda.']\n",
      "05/09 08:05:05 PM |\t  b_decoded[:2]:['Die Premierminister Indiens und Japans trafen sich in Tokio.', 'Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.', 'Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.', 'Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.']\n",
      "05/09 08:05:05 PM |\t  pred_a_decoded[:2]:['In Tokio treffen sich Premierminister Indiens und Japans', 'Der neue indische Premierminister Narendra Modi trifft sein japanisches Amtskollege Shinzo Abe in Tokio, um über Wirtschafts- und Sicherheitsbeziehungen zu diskutieren, und zwar zu seinem ersten großen Auslandsbesuch seit dem Sieg der Wahl im Mai.', 'Herr Modi ist in einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen zu der drittgrößten Volkswirtschaft der Welt zu stärken.', 'Auf der Tagesordnung stehen Pläne für eine verstärkte nukleare Zusammenarbeit.']\n",
      "05/09 08:05:40 PM |\t  computing score...\n",
      "05/09 08:05:40 PM |\t  G_AB GAB sacreBLEU : 24.670786\n",
      "05/09 08:05:40 PM |\t  G_BA GBA sacreBLEU : 22.709498\n",
      "05/09 08:05:40 PM |\t  G_AB GAB test loss : 5.643034\n",
      "05/09 08:05:40 PM |\t  G_BA GBA test loss : 10.486154\n",
      "05/09 08:05:40 PM |\t  \n",
      "\n",
      "  ----------------epoch:1----------------\n",
      "05/09 08:05:40 PM |\t  total iter:[500] \t G_lr:4.05e-05 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/09 08:07:15 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06839646443724633, 'GBA_once_meter': -0.053526336885988714, 'DA_meter': -0.003237821776419878, 'DB_meter': 0.0031768493074923756, 'DA_GP_meter': 0.07884297177195548, 'DB_GP_meter': 0.10883019626140594}\n",
      "05/09 08:07:15 PM |\t  19.2%\n",
      "05/09 08:08:46 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.06876432806253434, 'GBA_once_meter': -0.06037441909313202, 'DA_meter': 0.002070092111825943, 'DB_meter': -0.002172405980527401, 'DA_GP_meter': 0.07665586531162262, 'DB_GP_meter': 0.09867355853319168}\n",
      "05/09 08:08:46 PM |\t  39.2%\n",
      "05/09 08:10:33 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.07508948385715485, 'GBA_once_meter': -0.051921512819826605, 'DA_meter': 0.0014560487121343612, 'DB_meter': 0.00018941126763820647, 'DA_GP_meter': 0.07896339401602745, 'DB_GP_meter': 0.08128708735108375}\n",
      "05/09 08:10:33 PM |\t  59.199999999999996%\n",
      "05/09 08:12:06 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.07846824467182159, 'GBA_once_meter': -0.045510751716792586, 'DA_meter': 0.0023077946156263352, 'DB_meter': -0.0009476497210562229, 'DA_GP_meter': 0.0892050814628601, 'DB_GP_meter': 0.08083149194717407}\n",
      "05/09 08:12:06 PM |\t  79.2%\n",
      "05/09 08:13:46 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.07481829687952996, 'GBA_once_meter': -0.0363519511371851, 'DA_meter': 0.0004433535411953926, 'DB_meter': -0.008376167584210635, 'DA_GP_meter': 0.07931585475802422, 'DB_GP_meter': 0.2337555593252182}\n",
      "05/09 08:13:46 PM |\t  99.2%\n",
      "05/09 08:13:54 PM |\t  DB_a_: 0.036,  0.049,  0.069,  0.063,  \n",
      "05/09 08:13:54 PM |\t  DB_pred_dis: 0.005,  0.046,  0.076,  0.062,  \n",
      "05/09 08:13:54 PM |\t  DA_b: -0.08,  -0.03,  -0.09,  -0.09,  \n",
      "05/09 08:13:54 PM |\t  DA_pred_dis: -0.07,  -0.04,  -0.09,  -0.08,  \n",
      "05/09 08:13:54 PM |\t  GABloss:\t3.70712947845459\n",
      "05/09 08:13:54 PM |\t  GBAloss:\t10.840747833251953\n",
      "05/09 08:13:54 PM |\t  a_decoded[:2]:['India and Japan prime ministers meet in Tokyo', \"India's new prime minister, Narendra Modi, is meeting his Japanese counterpart, Shinzo Abe, in Tokyo to discuss economic and security ties, on his first major foreign visit since winning May's election.\", 'Mr Modi is on a five-day trip to Japan to strengthen economic ties with the third largest economy in the world.', 'High on the agenda are plans for greater nuclear co-operation.']\n",
      "05/09 08:13:54 PM |\t  pred_b_decoded[:2]:['The Prime Minister of India and Japan met in Tokyo.', 'Prime Minister Narendra Modi, who is the first to visit India since his election victory in May, will meet his Japanese counterpart Shinzo Abe in Toko in order to discuss economic and security policy.', 'Mr Modi is on a five-day trip to Japan to consolidate economic relations with the third largest economic nation in the world.', 'More nuclear cooperation is on the agenda.']\n",
      "05/09 08:13:54 PM |\t  b_decoded[:2]:['Die Premierminister Indiens und Japans trafen sich in Tokio.', 'Indiens neuer Premierminister Narendra Modi trifft bei seinem ersten wichtigen Auslandsbesuch seit seinem Wahlsieg im Mai seinen japanischen Amtskollegen Shinzo Abe in Toko, um wirtschaftliche und sicherheitspolitische Beziehungen zu besprechen.', 'Herr Modi befindet sich auf einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Wirtschaftsnation der Welt zu festigen.', 'Pläne für eine stärkere kerntechnische Zusammenarbeit stehen ganz oben auf der Tagesordnung.']\n",
      "05/09 08:13:54 PM |\t  pred_a_decoded[:2]:['In Tokio treffen sich Premierminister Indiens und Japans', 'Der neue Premierminister Narendra Modi trifft sein japanisches Amt Shinzo Abe in Tokio, um über wirtschaftliche und Sicherheitsbeziehungen zu diskutieren, als er seinen ersten großen Auslandsbesuch nach dem Sieg der Wahl im Mai feierte.', 'Herr Modi ist in einer fünftägigen Reise nach Japan, um die wirtschaftlichen Beziehungen mit der drittgrößten Volkswirtschaft der Welt zu stärken.', 'Auf der Tagesordnung stehen Pläne für eine verstärkte nukleare Zusammenarbeit.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_126116/2913806740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycleGAN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\train.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(loader, model, total_iter, args, logging, valid_loader, tokenizer, wandb)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG_AB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"G_AB.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mG_BA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"G_BA.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mmy_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\test.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(loader, model, tokenizer, logging, wandb)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0ma_generate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mb_generate\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mGBA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\basic_model.py\u001b[0m in \u001b[0;36mtest_generate\u001b[1;34m(self, x, num_beams, max_length)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenzied_prefix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m             )\n\u001b[0;32m   1314\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1316\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   2159\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;31m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;31m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m         \u001b[0mextended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_extended_attention_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mget_extended_attention_mask\u001b[1;34m(self, attention_mask, input_shape, device)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;31m# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m                 extended_attention_mask = self.create_extended_attention_mask_for_decoder(\n\u001b[0m\u001b[0;32m    567\u001b[0m                     \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mcreate_extended_attention_mask_for_decoder\u001b[1;34m(self, input_shape, attention_mask, device)\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;31m# in case past_key_values are used we need to add a prefix ones mask to the causal mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;31m# causal and attention masks must have same type with pytorch version < 1.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[0mcausal_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
