{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "from parameter import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 500\n",
      "args.rep_iter 100\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 300, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 1000, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=4,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=128,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=5e-6,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--G_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--G_grad_clip', type=float,                default=1,   help='grad_clip')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=5e-5,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--D_gamma', type=float,                    default=1,    help='lr*gamma after each test')\n",
    "    parser.add_argument('--D_grad_clip', type=float,                default=1e-2,   help='grad_clip')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=1,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=0,   help='')\n",
    "    parser.add_argument('--lambda_GP', type=float,                  default=10,   help='WGANGP pentalty')\n",
    "    parser.add_argument('--DperG', type=int,                        default=2,    help='n_critc')\n",
    "    parser.add_argument('--GperD', type=int,                        default=2,    help='n_g')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.5,    help='labelsmoothing')\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--load_G', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--num_workers', type=int,                  default=0,      help='num_workers')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=0,      help='whether valid before train')\n",
    "    parser.add_argument('--poolsize', type=int,                     default=1,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220518_151800-1urrkakh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/1urrkakh\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/cycleWMT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/cycleWMT/runs/1urrkakh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x13751762b80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"cycleWMT\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/18 03:18:07 PM |\t  Namespace(D_A_model_name='Onlydrinkwater/T5-small-de-en', D_B_model_name='t5-small', D_gamma=1, D_grad_clip=0.01, D_lr=5e-05, D_pretrain_iter=0, D_weight_decay=0.001, DperG=2, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_gamma=1, G_grad_clip=1, G_lr=5e-06, G_weight_decay=0.001, GperD=2, batch_size=4, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=1, lambda_B=1, lambda_GP=10, lambda_identity=0.5, lambda_once=0, load_D=0, load_G=0, max_length=128, num_workers=0, poolsize=1, rep_iter=100, smoothing=0.5, test_iter=500, train_D=1, train_G=1, train_num_points=1000, valid_begin=1, valid_num_points=300)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/18 03:18:12 PM |\t  Gmodelsize:60.506624MB\n",
      "05/18 03:18:12 PM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/18 03:18:16 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16',language+'-en')#load_dataset(\"bible_para\", lang1=\"de\", lang2=\"en\")\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['validation']['translation'][-args.valid_num_points:]#TODO:\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=args.num_workers>0, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/18 03:18:59 PM |\t  DB_a_: -0.19,  -0.15,  -0.15,  -0.10,  \n",
      "05/18 03:18:59 PM |\t  DB_pred_dis: -0.17,  -0.11,  -0.17,  -0.09,  \n",
      "05/18 03:18:59 PM |\t  DA_b: 0.042,  0.066,  0.063,  0.066,  \n",
      "05/18 03:18:59 PM |\t  DA_pred_dis: 0.047,  0.066,  0.102,  0.077,  \n",
      "05/18 03:18:59 PM |\t  GABloss:\t4.895842552185059\n",
      "05/18 03:18:59 PM |\t  GBAloss:\t10.294256210327148\n",
      "05/18 03:18:59 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/18 03:18:59 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', '.', \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/18 03:18:59 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/18 03:18:59 PM |\t  pred_a_decoded[:2]:['Er lernte diese Lektion auf hartem Wege.', 'Während der letzten vier Wochen wurde er in der College-Reisebuchhandlung vollen Preis bezahlen.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/18 03:20:48 PM |\t  computing score...\n",
      "05/18 03:20:49 PM |\t  G_AB GAB sacreBLEU : 24.411364\n",
      "05/18 03:20:49 PM |\t  G_BA GBA sacreBLEU : 21.171817\n",
      "05/18 03:20:49 PM |\t  G_AB GAB test loss : 5.302500\n",
      "05/18 03:20:49 PM |\t  G_BA GBA test loss : 8.912396\n",
      "05/18 03:20:49 PM |\t  D_A DA test loss : 0.004107\n",
      "05/18 03:20:49 PM |\t  D_B DB test loss : -0.005118\n",
      "05/18 03:20:49 PM |\t  D_A DA test accuracy : 0.450000\n",
      "05/18 03:20:49 PM |\t  D_B DB test accuracy : 0.546667\n",
      "05/18 03:20:49 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "05/18 03:20:49 PM |\t  total iter:[0] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/18 03:22:24 PM |\t  {'GB_cycle_meter': 10.300937096277872, 'GA_cycle_meter': 10.272092898686727, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.012832869216799736, 'DB_meter': -0.005784717351198196, 'DA_GP_meter': 0.01763846553862095, 'DB_GP_meter': 0.06596682354807853}\n",
      "05/18 03:22:24 PM |\t  9.6%\n",
      "05/18 03:24:00 PM |\t  {'GB_cycle_meter': 10.281184355417887, 'GA_cycle_meter': 10.232700030008951, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.007355913668870926, 'DB_meter': 0.011179905980825425, 'DA_GP_meter': 0.016667748261243107, 'DB_GP_meter': 0.05389046169817448}\n",
      "05/18 03:24:00 PM |\t  19.6%\n",
      "05/18 03:25:42 PM |\t  {'GB_cycle_meter': 10.288600334754356, 'GA_cycle_meter': 10.228012818556566, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.007070973627269268, 'DB_meter': -0.0059352325275540355, 'DA_GP_meter': 0.013414438497275114, 'DB_GP_meter': 0.06150745773687959}\n",
      "05/18 03:25:42 PM |\t  29.599999999999998%\n",
      "05/18 03:27:22 PM |\t  {'GB_cycle_meter': 10.274590333302816, 'GA_cycle_meter': 10.22255023320516, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.006292255092412233, 'DB_meter': -0.004665760286152363, 'DA_GP_meter': 0.00991702064871788, 'DB_GP_meter': 0.04433813579380512}\n",
      "05/18 03:27:22 PM |\t  39.6%\n",
      "05/18 03:28:59 PM |\t  {'GB_cycle_meter': 10.25018493945782, 'GA_cycle_meter': 10.220931419959435, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.009927369207143783, 'DB_meter': 0.001541301365941763, 'DA_GP_meter': 0.007296577226370573, 'DB_GP_meter': 0.0072972379392012955}\n",
      "05/18 03:28:59 PM |\t  49.6%\n",
      "05/18 03:29:07 PM |\t  DB_a_: -0.04,  -0.04,  -0.05,  -0.04,  \n",
      "05/18 03:29:07 PM |\t  DB_pred_dis: -0.04,  -0.04,  -0.04,  -0.03,  \n",
      "05/18 03:29:07 PM |\t  DA_b: 0.020,  0.041,  0.042,  0.073,  \n",
      "05/18 03:29:07 PM |\t  DA_pred_dis: 0.008,  0.049,  0.048,  0.081,  \n",
      "05/18 03:29:07 PM |\t  GABloss:\t5.14103364944458\n",
      "05/18 03:29:07 PM |\t  GBAloss:\t10.625977516174316\n",
      "05/18 03:29:07 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/18 03:29:07 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why was 'Guardians of the Galaxy' not a rocket bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/18 03:29:07 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/18 03:29:07 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf hartem Wege gelernt.', 'Während der letzten vier Wochen wurde ein Buch gekauft, und er zahlte schließlich den vollen Preis in der College Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For lediglich 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/18 03:31:01 PM |\t  computing score...\n",
      "05/18 03:31:01 PM |\t  G_AB GAB sacreBLEU : 25.495061\n",
      "05/18 03:31:01 PM |\t  G_BA GBA sacreBLEU : 21.292852\n",
      "05/18 03:31:01 PM |\t  G_AB GAB test loss : 5.452638\n",
      "05/18 03:31:01 PM |\t  G_BA GBA test loss : 9.278698\n",
      "05/18 03:31:01 PM |\t  D_A DA test loss : -0.003397\n",
      "05/18 03:31:01 PM |\t  D_B DB test loss : 0.000308\n",
      "05/18 03:31:01 PM |\t  D_A DA test accuracy : 0.583333\n",
      "05/18 03:31:01 PM |\t  D_B DB test accuracy : 0.456667\n",
      "05/18 03:32:37 PM |\t  {'GB_cycle_meter': 10.233678897221884, 'GA_cycle_meter': 10.215156237284342, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': 0.00033019326627254487, 'DB_meter': -0.00010195218026638032, 'DA_GP_meter': 0.0026572098443284633, 'DB_GP_meter': 0.0006818920955993235}\n",
      "05/18 03:32:37 PM |\t  59.599999999999994%\n",
      "05/18 03:34:08 PM |\t  {'GB_cycle_meter': 10.196950472318209, 'GA_cycle_meter': 10.156366201547476, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0022496751882135867, 'DB_meter': -0.0008124918118119239, 'DA_GP_meter': 0.0023522248212248086, 'DB_GP_meter': 0.0007908737799152732}\n",
      "05/18 03:34:08 PM |\t  69.6%\n",
      "05/18 03:35:39 PM |\t  {'GB_cycle_meter': 10.148194074630737, 'GA_cycle_meter': 10.129558642705282, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0020385263673961163, 'DB_meter': 0.0004586777836084366, 'DA_GP_meter': 0.0023002632474526763, 'DB_GP_meter': 0.00033028394915163517}\n",
      "05/18 03:35:39 PM |\t  79.60000000000001%\n",
      "05/18 03:37:05 PM |\t  {'GB_cycle_meter': 10.21933181469257, 'GA_cycle_meter': 10.185896286597618, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0052976453676819805, 'DB_meter': -0.0012852806597948075, 'DA_GP_meter': 0.002481172047555447, 'DB_GP_meter': 0.00024008905631490052}\n",
      "05/18 03:37:05 PM |\t  89.60000000000001%\n",
      "05/18 03:38:40 PM |\t  {'GB_cycle_meter': 10.234087387720743, 'GA_cycle_meter': 10.190390666325888, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': 0.0005914097093045711, 'DB_meter': -0.000648040696978569, 'DA_GP_meter': 0.002215176997706294, 'DB_GP_meter': 0.000296174623654224}\n",
      "05/18 03:38:40 PM |\t  99.6%\n",
      "05/18 03:38:48 PM |\t  DB_a_: -0.05,  -0.05,  -0.05,  -0.05,  \n",
      "05/18 03:38:48 PM |\t  DB_pred_dis: -0.05,  -0.05,  -0.05,  -0.04,  \n",
      "05/18 03:38:48 PM |\t  DA_b: 0.014,  0.040,  0.037,  0.053,  \n",
      "05/18 03:38:48 PM |\t  DA_pred_dis: 0.004,  0.027,  0.041,  0.058,  \n",
      "05/18 03:38:48 PM |\t  GABloss:\t5.695315361022949\n",
      "05/18 03:38:48 PM |\t  GBAloss:\t11.086386680603027\n",
      "05/18 03:38:48 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/18 03:38:48 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/18 03:38:48 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/18 03:38:48 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf hartem Wege gelernt.', 'Er hat ein Buch gekauft, das vier Wochen lang zurückbestellt wurde, und schließlich zahlte er den vollen Preis in der College-Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/18 03:40:36 PM |\t  computing score...\n",
      "05/18 03:40:36 PM |\t  G_AB GAB sacreBLEU : 25.643309\n",
      "05/18 03:40:36 PM |\t  G_BA GBA sacreBLEU : 21.735787\n",
      "05/18 03:40:36 PM |\t  G_AB GAB test loss : 5.761622\n",
      "05/18 03:40:36 PM |\t  G_BA GBA test loss : 9.783948\n",
      "05/18 03:40:36 PM |\t  D_A DA test loss : -0.008449\n",
      "05/18 03:40:36 PM |\t  D_B DB test loss : -0.000281\n",
      "05/18 03:40:36 PM |\t  D_A DA test accuracy : 0.670000\n",
      "05/18 03:40:36 PM |\t  D_B DB test accuracy : 0.506667\n",
      "05/18 03:40:36 PM |\t  \n",
      "\n",
      "  ----------------epoch:1----------------\n",
      "05/18 03:40:36 PM |\t  total iter:[1000] \t G_lr:5e-06 \t DA_lr:5e-05 \t DB_lr:5e-05\n",
      "05/18 03:42:13 PM |\t  {'GB_cycle_meter': 10.184047301610311, 'GA_cycle_meter': 10.212612311045328, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.009943060539662839, 'DB_meter': 0.0015451947413384914, 'DA_GP_meter': 0.005486024674028158, 'DB_GP_meter': 0.0014622862747637555}\n",
      "05/18 03:42:13 PM |\t  9.6%\n",
      "05/18 03:43:46 PM |\t  {'GB_cycle_meter': 10.268153349558512, 'GA_cycle_meter': 10.241846640904745, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.005130718499422073, 'DB_meter': -0.002393205352127552, 'DA_GP_meter': 0.005945038497447968, 'DB_GP_meter': 0.0004726804664824158}\n",
      "05/18 03:43:46 PM |\t  19.6%\n",
      "05/18 03:45:23 PM |\t  {'GB_cycle_meter': 10.27337646484375, 'GA_cycle_meter': 10.247472689701961, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.009227385222911834, 'DB_meter': 0.0005566389858722687, 'DA_GP_meter': 0.00506531591527164, 'DB_GP_meter': 0.00040704896644456313}\n",
      "05/18 03:45:23 PM |\t  29.599999999999998%\n",
      "05/18 03:47:01 PM |\t  {'GB_cycle_meter': 10.236764192581177, 'GA_cycle_meter': 10.2130446434021, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.022073260508477688, 'DB_meter': -0.00017965799197554587, 'DA_GP_meter': 0.005161337414756417, 'DB_GP_meter': 0.0002448173973243684}\n",
      "05/18 03:47:01 PM |\t  39.6%\n",
      "05/18 03:48:40 PM |\t  {'GB_cycle_meter': 10.273549299973707, 'GA_cycle_meter': 10.211575434758114, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.0188294630125165, 'DB_meter': -0.0008515369147062302, 'DA_GP_meter': 0.004863317115232349, 'DB_GP_meter': 0.00017372943329974078}\n",
      "05/18 03:48:40 PM |\t  49.6%\n",
      "05/18 03:48:47 PM |\t  DB_a_: -0.06,  -0.06,  -0.06,  -0.06,  \n",
      "05/18 03:48:47 PM |\t  DB_pred_dis: -0.06,  -0.06,  -0.06,  -0.06,  \n",
      "05/18 03:48:47 PM |\t  DA_b: 0.008,  0.042,  0.051,  0.058,  \n",
      "05/18 03:48:47 PM |\t  DA_pred_dis: 0.001,  0.020,  0.043,  0.069,  \n",
      "05/18 03:48:47 PM |\t  GABloss:\t6.298251152038574\n",
      "05/18 03:48:47 PM |\t  GBAloss:\t11.496230125427246\n",
      "05/18 03:48:47 PM |\t  a_decoded[:2]:['He learned that lesson the hard way.', 'A book he purchased was back-ordered for four weeks, and he ended up paying full price at the college bookstore.', \"Why the Guardians of the Galaxy couldn't save the box office\", \"Sylvester Stallone's The Expendables 3 has made back less than $30 million of its $90 million budget in the US, while Sin City: A Dame to Kill For has made back only $12 million of its $70 million budget.\"]\n",
      "05/18 03:48:47 PM |\t  pred_b_decoded[:2]:['He has learned this lesson on the hard road.', 'He bought a book that had four weeks of delivery and finally paid the full price in the College bookstore.', \"Why 'Guardians of the Galaxy' was not a bomber?\", \"The 'Expendable 3' by Sylvester Stallone played less than USD 30 million in his 90 million budget in the United States, while 'Sin City: A Lady To Kill For' played only USD 12 million in his 70 million budget.\"]\n",
      "05/18 03:48:47 PM |\t  b_decoded[:2]:['Diese Lektion lernte er auf die harte Tour.', 'Er kaufte ein Buch, dass vier Wochen Lieferzeit hatte und zahlte schließlich den vollen Preis im College-Buchladen.', 'Warum \"Guardians of the Galaxy\" kein Kassenschlager wurde', '\"The Expendables 3\" von Sylvester Stallone spielte weniger als 30 Millionen Dollar seines 90 Millionen Dollar Budgets in den USA ein, während \"Sin City: A Dame to Kill For\" lediglich 12 Millionen Dollar seines Budgets von 70 Millionen Dollar einspielte.']\n",
      "05/18 03:48:47 PM |\t  pred_a_decoded[:2]:['Er hat diese Lektion auf hartem Wege gelernt.', 'Ein Buch, das er erworben hat, wurde vier Wochen lang zurückbestellt, und er zahlte schließlich den vollen Preis in der College-Buchhandlung.', 'Warum die Guardians of the Galaxy die Box Office nicht retten konnten', 'Die Ausgaben 3 von Sylvester Stallone hat weniger als 30 Millionen Dollar aus ihrem 90 Millionen Dollar Budget in den USA zurückerstattet, während Sin City: A Dame to Kill For nur 12 Millionen Dollar aus ihrem 70 Millionen Dollar Budget zurückerstattet hat.']\n",
      "05/18 03:50:37 PM |\t  computing score...\n",
      "05/18 03:50:37 PM |\t  G_AB GAB sacreBLEU : 25.800333\n",
      "05/18 03:50:37 PM |\t  G_BA GBA sacreBLEU : 21.603198\n",
      "05/18 03:50:37 PM |\t  G_AB GAB test loss : 6.151058\n",
      "05/18 03:50:37 PM |\t  G_BA GBA test loss : 10.245518\n",
      "05/18 03:50:37 PM |\t  D_A DA test loss : -0.010295\n",
      "05/18 03:50:37 PM |\t  D_B DB test loss : -0.000194\n",
      "05/18 03:50:37 PM |\t  D_A DA test accuracy : 0.693333\n",
      "05/18 03:50:37 PM |\t  D_B DB test accuracy : 0.550000\n",
      "05/18 03:52:08 PM |\t  {'GB_cycle_meter': 10.224789698918661, 'GA_cycle_meter': 10.129700978597006, 'GAB_once_meter': 0.0, 'GBA_once_meter': 0.0, 'DA_meter': -0.019077577888965608, 'DB_meter': -0.00011959806084632874, 'DA_GP_meter': 0.0026197415217757225, 'DB_GP_meter': 2.8544359884108418e-05}\n",
      "05/18 03:52:08 PM |\t  59.599999999999994%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_262564/2913806740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycleGAN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\train.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(loader, model, total_iter, args, logging, valid_loader, tokenizer, wandb)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             '''\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGperD\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\cycle.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self, trainD, trainG)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# set D_A and D_B's gradients to zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# set D_A and D_B's gradients to zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_D_A\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# calculate gradients for D_A\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_D_B\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# calculate graidents for D_B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# update D_A and D_B's weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\cycle.py\u001b[0m in \u001b[0;36mbackward_D_A\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_B_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mloss_D\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_GP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_D_basic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_B_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;31m# onehot = torch.zeros((self.real_A.shape[0],self.real_A.shape[1],fake_B.shape[-1]), device=torch.device('cuda:0'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;31m# onehot_real_A = onehot.scatter_(-1,self.real_A.unsqueeze(-1),1).float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\cycle.py\u001b[0m in \u001b[0;36mbackward_D_basic\u001b[1;34m(self, D, real, real_attn, fake, fake_attn)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgradient_penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradient_penalty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m##TODO: add lose D(de) - D(en)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\kevin\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
