{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 498\n",
      "args.rep_iter 99\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 200, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 1000, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=3,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=512,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_num', type=int,                      default=25,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_num', type=int,                     default=4,      help='test times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=0.00001,   help='learning rate for G')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=0.00001,   help='learning rate for D')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=1,   help='')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=100,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220427_110841-zwz76p7o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/zwz76p7o\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/zwz76p7o?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x20e2ad06f40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"CYCLEGAN\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 11:08:49 AM |\t  Namespace(D_A_model_name='t5-small', D_B_model_name='Onlydrinkwater/T5-small-de-en', D_lr=1e-05, D_pretrain_iter=100, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_lr=1e-05, batch_size=3, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=0.01, lambda_B=0.01, lambda_identity=0.5, lambda_once=0, max_length=512, rep_iter=99, rep_num=25, smoothing=0.1, test_iter=498, test_num=4, train_D=1, train_G=1, train_num_points=1000, valid_begin=1, valid_num_points=200)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 11:08:54 AM |\t  Gmodelsize:60.506624MB\n",
      "04/27 11:08:54 AM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 11:08:58 AM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16','de-en')\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][args.train_num_points:(args.train_num_points+args.valid_num_points)]\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=RandomSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 11:16:38 AM |\t  GABloss:\t7.9060773849487305\n",
      "04/27 11:16:38 AM |\t  GBAloss:\t14.278043746948242\n",
      "04/27 11:16:38 AM |\t  a_decoded[:2]:['Commissioner Monti and his colleagues have a tremendous challenge ahead of them and our worries in the ELDR Group are that there should be no weakening in the thrust of competition policy either in the examination of mergers or the monitoring of restrictive practices.', 'If we want there to be competition then we must establish this link between the requirements of the national economy and the pre-requisites of managerial economics.']\n",
      "04/27 11:16:38 AM |\t  pred_b_decoded[:2]:['Mr Monti and his colleagues are facing a huge task, and we in the Group of the European Liberal, Democrat and Reform Party believe that competition policy must be safeguarded with regard to the investigation of mergers or the monitoring of restrictive behaviour.', 'If we want to have competition, we have to fight this division between economic needs and operational conditions.']\n",
      "04/27 11:16:38 AM |\t  b_decoded[:2]:['Kommissionsmitglied Monti und seine Kollegen stehen vor einer gigantischen Aufgabe, und wir in der ELDR-Fraktion meinen, daß die Schlagkraft der Wettbewerbspolitik in bezug auf die Untersuchung von Fusionen oder die Überwachung von wettbewerbsbeschränkendem Verhalten bewahrt werden muß.', 'Wenn wir Wettbewerb haben wollen, dann müssen wir diese Kopplung zwischen den volkswirtschaftlichen Notwendigkeiten und den betriebswirtschaftlichen Voraussetzungen hinkriegen.']\n",
      "04/27 11:16:38 AM |\t  pred_a_decoded[:2]:['Herr Kommissar Monti und seine Kollegen haben eine große Herausforderung vor sich, und unsere Bedenken in der ELDR-Fraktion sind, dass es weder bei der Prüfung von Fusionen noch bei der Überwachung restriktiver Praktiken eine Schwächung der Wettbewerbspolitik geben sollte.', 'Wenn wir wollen, dass es Wettbewerb gibt, dann müssen wir diese Verbindung zwischen den Anforderungen der nationalen Wirtschaft und den Voraussetzungen für die Führungswirtschaft herstellen.']\n",
      "04/27 11:18:32 AM |\t  computing score...\n",
      "04/27 11:18:32 AM |\t  G_AB GAB sacreBLEU : 21.034962\n",
      "04/27 11:18:32 AM |\t  G_BA GBA sacreBLEU : 28.626039\n",
      "04/27 11:18:32 AM |\t  G_AB GAB test loss : 7.962121\n",
      "04/27 11:18:32 AM |\t  G_BA GBA test loss : 12.130407\n",
      "04/27 11:18:32 AM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "04/27 11:20:00 AM |\t  {'GB_cycle_meter': 9.566739920413855, 'GA_cycle_meter': 9.624064142053777, 'GAB_once_meter': 0.8723902160471136, 'GBA_once_meter': 0.8684622573130059, 'DA_meter': 0.2707515209913254, 'DB_meter': 0.3767541889665705}\n",
      "04/27 11:20:00 AM |\t  \t\t19.46107784431138%\n",
      "04/27 11:20:50 AM |\t  {'GB_cycle_meter': 9.579702839706883, 'GA_cycle_meter': 9.639811891497988, 'GAB_once_meter': 0.8132537242138025, 'GBA_once_meter': 0.798356274763743, 'DA_meter': 0.10403424569151619, 'DB_meter': 0.2219563749703494}\n",
      "04/27 11:20:50 AM |\t  \t\t29.34131736526946%\n",
      "04/27 11:21:39 AM |\t  {'GB_cycle_meter': 9.595672029437441, 'GA_cycle_meter': 9.587763584021365, 'GAB_once_meter': 0.7611972798000682, 'GBA_once_meter': 0.7724930120236946, 'DA_meter': 0.079728639825727, 'DB_meter': 0.16697592852693616}\n",
      "04/27 11:21:39 AM |\t  \t\t39.221556886227546%\n",
      "04/27 11:22:27 AM |\t  {'GB_cycle_meter': 9.566186673713453, 'GA_cycle_meter': 9.617575674346, 'GAB_once_meter': 0.7714605340451905, 'GBA_once_meter': 0.7587614312316432, 'DA_meter': 0.04930755829043461, 'DB_meter': 0.13828686173215057}\n",
      "04/27 11:22:27 AM |\t  \t\t49.101796407185624%\n",
      "04/27 11:22:34 AM |\t  GABloss:\t10.683765411376953\n",
      "04/27 11:22:34 AM |\t  GBAloss:\t14.063210487365723\n",
      "04/27 11:22:34 AM |\t  a_decoded[:2]:['Commissioner, I am asking these questions as a defender of the internal market and I hope that, in this sense, we are all partners and that the discussion between these partners does not remain sterile but can bear fruit.', 'I find it difficult to understand how he can index regional and social funds into this mathematical equation.']\n",
      "04/27 11:22:34 AM |\t  pred_b_decoded[:2]:['Mr President, Commissioner, I am in favour of these issues as a supporter of the internal market and in the hope that, in this sense, we are all partners and that the dialogue between these partners will not be sterile but will bring success.', 'I find it difficult to understand how it can incorporate regional and social funds into this mathematical equation.']\n",
      "04/27 11:22:34 AM |\t  b_decoded[:2]:['Herr Kommissar, ich werfe diese Fragen als Befürworterin des Binnenmarkts und in der Hoffnung auf, daß wir hier in diesem Sinne alle Partner sind und daß das Gespräch zwischen diesen Partnern nicht steril bleibt, sondern Erfolge bringt.', 'Ich kann nur schwer nachvollziehen, wie er Regional- und Sozialfonds in diese mathematische Gleichung einbeziehen kann.']\n",
      "04/27 11:22:34 AM |\t  pred_a_decoded[:2]:['Herr Kommissar, ich stelle diese Fragen als Verteidiger des Binnenmarktes, und ich hoffe, dass wir in diesem Sinne alle Partner sind und dass die Diskussion zwischen diesen Partnern nicht steril bleibt, sondern Früchte tragen kann.', 'Portugiesisch fällt es mir schwer zu verstehen, wie er die Regional- und Sozialfonds in diese mathematische Gleichung integrieren kann.']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32236/3939261347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycleGAN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#TODO:cycgan.savemodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\train.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(loader, model, total_iter, args, logging, valid_loader, tokenizer, wandb)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\t\\t{step/len(loader)*100}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_iter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtotal_iter\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_pretrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\test.py\u001b[0m in \u001b[0;36mmy_test\u001b[1;34m(loader, model, tokenizer, logging, wandb)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0ma_generate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mb_generate\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mGBA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\basic_model.py\u001b[0m in \u001b[0;36mtest_generate\u001b[1;34m(self, x, num_beams, max_length)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenzied_prefix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0moutput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_attn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[0;32m   1313\u001b[0m             )\n\u001b[0;32m   1314\u001b[0m             \u001b[1;31m# 12. run beam search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m             return self.beam_search(\n\u001b[0m\u001b[0;32m   1316\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m             outputs = self(\n\u001b[0m\u001b[0;32m   2159\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;31m# Decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[0;32m   1639\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    965\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_hidden_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[0mencoder_extended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_attention_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mencoder_extended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36minvert_attention_mask\u001b[1;34m(self, encoder_attention_mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# encoder_extended_attention_mask = (encoder_extended_attention_mask ==\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;31m# encoder_extended_attention_mask.transpose(-1, -2))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0mencoder_extended_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# fp16 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = 0    \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "    # my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "    #TODO:cycgan.savemodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
