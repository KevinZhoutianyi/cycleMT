{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 498\n",
      "args.rep_iter 99\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 500, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=3,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=512,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_num', type=int,                      default=25,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_num', type=int,                     default=4,      help='test times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=0.001,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=0.00001,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=1,   help='')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=0,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=0,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220428_001744-337scrpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/337scrpg\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/337scrpg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x134fa4498b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"CYCLEGAN\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/28 12:17:52 AM |\t  Namespace(D_A_model_name='t5-small', D_B_model_name='Onlydrinkwater/T5-small-de-en', D_lr=1e-05, D_pretrain_iter=0, D_weight_decay=0.001, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_lr=0.0001, G_weight_decay=0.001, batch_size=3, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=0, lambda_B=0, lambda_identity=0.5, lambda_once=1, load_D=0, max_length=512, rep_iter=99, rep_num=25, smoothing=0.1, test_iter=498, test_num=4, train_D=1, train_G=1, train_num_points=500, valid_begin=0, valid_num_points=100)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/28 12:17:57 AM |\t  Gmodelsize:60.506624MB\n",
      "04/28 12:17:57 AM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/28 12:18:02 AM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 29.93it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16','de-en')\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][args.train_num_points:(args.train_num_points+args.valid_num_points)]\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 11:36:51 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "04/27 11:36:51 PM |\t  total iter:[0]\n",
      "04/27 11:37:42 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.8501399285865553, 'GBA_once_meter': 0.8667336467540625, 'DA_meter': 0.25829156533335196, 'DB_meter': 0.2403554062951695}\n",
      "04/27 11:37:42 PM |\t  \t\t19.16167664670659%\n",
      "04/27 11:38:27 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.7915417100443984, 'GBA_once_meter': 0.7934112855882356, 'DA_meter': 0.06977603708704312, 'DB_meter': 0.07612254730228221}\n",
      "04/27 11:38:27 PM |\t  \t\t38.92215568862276%\n",
      "04/27 11:39:13 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.8356614582466356, 'GBA_once_meter': 0.801476591464245, 'DA_meter': 0.028960790019482374, 'DB_meter': 0.0563353519378738}\n",
      "04/27 11:39:13 PM |\t  \t\t58.68263473053892%\n",
      "04/27 11:39:58 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.891163378050833, 'GBA_once_meter': 0.8162263035774231, 'DA_meter': 0.013703087013158383, 'DB_meter': 0.03382363315728126}\n",
      "04/27 11:39:58 PM |\t  \t\t78.44311377245509%\n",
      "04/27 11:40:42 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9246061931956898, 'GBA_once_meter': 0.8406977129705024, 'DA_meter': 0.012782115670922918, 'DB_meter': 0.020322682632302694}\n",
      "04/27 11:40:42 PM |\t  \t\t98.20359281437125%\n",
      "04/27 11:40:50 PM |\t  GABloss:\t6.766984939575195\n",
      "04/27 11:40:50 PM |\t  GBAloss:\t12.368963241577148\n",
      "04/27 11:40:50 PM |\t  a_decoded[:2]:['Past experience dictates that, as the elected representatives of the European taxpayer, we should, and indeed must, demand financial probity and transparency in the disbursement and auditing of this money, hence our amendments and additions relate to achieving what are known as \"value for money\" indicators in the grant-giving process.', 'Next, we all too often see vast sums of money being spent on projects whose outcomes will necessarily be unclear at the start of the programme period.']\n",
      "04/27 11:40:50 PM |\t  pred_b_decoded[:2]:['The past has shown us that we, as elected representatives of the European taxpayers, should demand financial redundancy and transparency in the payment of these funds and the auditing that is involved, and our amendments and contributions aim to achieve what can be achieved by granting grants as an indicator of the most economically favourable solution.', 'Secondly, all too often, huge sums are being spent on projects, whose results are simply not being assessed clearly at the beginning of the programme.']\n",
      "04/27 11:40:50 PM |\t  b_decoded[:2]:['Die Erfahrungen der Vergangenheit zeigen, daß wir als die gewählten Vertreter der europäischen Steuerzahler finanzielle Redlichkeit und Transparenz bei der Auszahlung dieser Gelder und der damit verbundenen Rechnungsprüfung fordern sollten, ja müssen. Mit unseren nderungen und Zusätzen wollen wir das erreichen, was bei der Gewährung von Zuschüssen als Indikator für die wirtschaftlich günstigste Lösung dienen kann.', 'Zweitens fließen nur allzu oft riesige Summen in Projekte, deren Ergebnisse sich zu Beginn des Programmzeitraums einfach noch nicht klar abschätzen lassen.']\n",
      "04/27 11:40:50 PM |\t  pred_a_decoded[:2]:['Die Erfahrung der Vergangenheit legt fest, daß wir als gewählte Vertreter der europäischen Steuerzahler finanzielle Besonnenheit und Transparenz bei der Auszahlung und Prüfung dieses Geldes fordern müssen und daß es deshalb unsere nderungsanträge und Ergänzungen gibt, die sich auf die Erreichung der so genannten \"Value-for-money\"-Indikatoren im Förderverfahren beziehen.', 'Dann sehen wir allzu oft riesige Summen für Projekte, deren Ergebnisse zu Beginn des Programmzeitraums zwangsläufig unklar sein werden.']\n",
      "04/27 11:42:00 PM |\t  computing score...\n",
      "04/27 11:42:00 PM |\t  G_AB GAB sacreBLEU : 17.700678\n",
      "04/27 11:42:00 PM |\t  G_BA GBA sacreBLEU : 21.779081\n",
      "04/27 11:42:00 PM |\t  G_AB GAB test loss : 7.876427\n",
      "04/27 11:42:00 PM |\t  G_BA GBA test loss : 12.636821\n",
      "04/27 11:42:02 PM |\t  \n",
      "\n",
      "  ----------------epoch:1----------------\n",
      "04/27 11:42:02 PM |\t  total iter:[501]\n",
      "04/27 11:42:45 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9636408361521634, 'GBA_once_meter': 0.8966425819830461, 'DA_meter': 0.008803282984334863, 'DB_meter': 0.022099177958090986}\n",
      "04/27 11:42:45 PM |\t  \t\t17.964071856287426%\n",
      "04/27 11:43:29 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9639829487511606, 'GBA_once_meter': 0.9230976754968817, 'DA_meter': 0.005520772369698424, 'DB_meter': 0.020473324524408035}\n",
      "04/27 11:43:29 PM |\t  \t\t37.72455089820359%\n",
      "04/27 11:44:14 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.985286371274428, 'GBA_once_meter': 0.9282203515370687, 'DA_meter': 0.0038051198300143533, 'DB_meter': 0.009627991992712134}\n",
      "04/27 11:44:14 PM |\t  \t\t57.48502994011976%\n",
      "04/27 11:44:58 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9822787534106862, 'GBA_once_meter': 0.9462822278340658, 'DA_meter': 0.0020792224209854435, 'DB_meter': 0.006237099171178697}\n",
      "04/27 11:44:58 PM |\t  \t\t77.24550898203593%\n",
      "04/27 11:45:43 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9760416746139526, 'GBA_once_meter': 0.9282012636011298, 'DA_meter': 0.0019929983951221925, 'DB_meter': 0.008632794978576854}\n",
      "04/27 11:45:43 PM |\t  \t\t97.0059880239521%\n",
      "04/27 11:45:52 PM |\t  GABloss:\t5.602736473083496\n",
      "04/27 11:45:52 PM |\t  GBAloss:\t12.284058570861816\n",
      "04/27 11:45:52 PM |\t  a_decoded[:2]:['Past experience dictates that, as the elected representatives of the European taxpayer, we should, and indeed must, demand financial probity and transparency in the disbursement and auditing of this money, hence our amendments and additions relate to achieving what are known as \"value for money\" indicators in the grant-giving process.', 'Next, we all too often see vast sums of money being spent on projects whose outcomes will necessarily be unclear at the start of the programme period.']\n",
      "04/27 11:45:52 PM |\t  pred_b_decoded[:2]:['We need to be able to do so.', 'The second is that it is all too often, and it is all too often. The second is that it is all too often.']\n",
      "04/27 11:45:52 PM |\t  b_decoded[:2]:['Die Erfahrungen der Vergangenheit zeigen, daß wir als die gewählten Vertreter der europäischen Steuerzahler finanzielle Redlichkeit und Transparenz bei der Auszahlung dieser Gelder und der damit verbundenen Rechnungsprüfung fordern sollten, ja müssen. Mit unseren nderungen und Zusätzen wollen wir das erreichen, was bei der Gewährung von Zuschüssen als Indikator für die wirtschaftlich günstigste Lösung dienen kann.', 'Zweitens fließen nur allzu oft riesige Summen in Projekte, deren Ergebnisse sich zu Beginn des Programmzeitraums einfach noch nicht klar abschätzen lassen.']\n",
      "04/27 11:45:52 PM |\t  pred_a_decoded[:2]:['Die Erfahrungen der Vergangenheit diktieren, daß wir - und es muß gesagt werden - daß wir es fordern müssen - daß wir es fordern müssen - daß wir es fordern müssen - daß wir es fordern müssen - daß wir es fordern - daß wir es fordern - daß wir es fordern - daß wir ', 'Und es ist es ne stört es ne stört es ne stört es ne stört es ne stört es ne stört es ne stört es ne stört es ne stört ne stört ']\n",
      "04/27 11:48:38 PM |\t  computing score...\n",
      "04/27 11:48:39 PM |\t  G_AB GAB sacreBLEU : 3.509659\n",
      "04/27 11:48:39 PM |\t  G_BA GBA sacreBLEU : 0.853852\n",
      "04/27 11:48:39 PM |\t  G_AB GAB test loss : 6.082833\n",
      "04/27 11:48:39 PM |\t  G_BA GBA test loss : 13.481713\n",
      "04/27 11:48:41 PM |\t  \n",
      "\n",
      "  ----------------epoch:2----------------\n",
      "04/27 11:48:41 PM |\t  total iter:[1002]\n",
      "04/27 11:49:23 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9709301645105536, 'GBA_once_meter': 0.9426948590712114, 'DA_meter': 0.004331007994937174, 'DB_meter': 0.00642856458381919}\n",
      "04/27 11:49:23 PM |\t  \t\t16.766467065868262%\n",
      "04/27 11:50:08 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9755197311892654, 'GBA_once_meter': 0.9653044108188513, 'DA_meter': 0.002825883965036183, 'DB_meter': 0.005687322946455838}\n",
      "04/27 11:50:08 PM |\t  \t\t36.52694610778443%\n",
      "04/27 11:50:53 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9401149352391561, 'GBA_once_meter': 0.9743612769878272, 'DA_meter': 0.003532360145596392, 'DB_meter': 0.002802710107062012}\n",
      "04/27 11:50:53 PM |\t  \t\t56.287425149700596%\n",
      "04/27 11:51:37 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9052266586910594, 'GBA_once_meter': 0.9856901945489825, 'DA_meter': 0.008182784466595022, 'DB_meter': 0.007647837610089813}\n",
      "04/27 11:51:37 PM |\t  \t\t76.04790419161677%\n",
      "04/27 11:52:22 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9859464313044692, 'GBA_once_meter': 0.9737397739381501, 'DA_meter': 0.0021300678345141932, 'DB_meter': 0.008004475177696087}\n",
      "04/27 11:52:22 PM |\t  \t\t95.80838323353294%\n",
      "04/27 11:52:33 PM |\t  GABloss:\t4.8538641929626465\n",
      "04/27 11:52:33 PM |\t  GBAloss:\t12.728095054626465\n",
      "04/27 11:52:33 PM |\t  a_decoded[:2]:['Past experience dictates that, as the elected representatives of the European taxpayer, we should, and indeed must, demand financial probity and transparency in the disbursement and auditing of this money, hence our amendments and additions relate to achieving what are known as \"value for money\" indicators in the grant-giving process.', 'Next, we all too often see vast sums of money being spent on projects whose outcomes will necessarily be unclear at the start of the programme period.']\n",
      "04/27 11:52:33 PM |\t  pred_b_decoded[:2]:['We have we have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have. We have.', 'There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second. There is a second.']\n",
      "04/27 11:52:33 PM |\t  b_decoded[:2]:['Die Erfahrungen der Vergangenheit zeigen, daß wir als die gewählten Vertreter der europäischen Steuerzahler finanzielle Redlichkeit und Transparenz bei der Auszahlung dieser Gelder und der damit verbundenen Rechnungsprüfung fordern sollten, ja müssen. Mit unseren nderungen und Zusätzen wollen wir das erreichen, was bei der Gewährung von Zuschüssen als Indikator für die wirtschaftlich günstigste Lösung dienen kann.', 'Zweitens fließen nur allzu oft riesige Summen in Projekte, deren Ergebnisse sich zu Beginn des Programmzeitraums einfach noch nicht klar abschätzen lassen.']\n",
      "04/27 11:52:33 PM |\t  pred_a_decoded[:2]:['Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si Si', 'Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions Questions']\n",
      "04/27 11:55:08 PM |\t  computing score...\n",
      "04/27 11:55:08 PM |\t  G_AB GAB sacreBLEU : 0.005645\n",
      "04/27 11:55:08 PM |\t  G_BA GBA sacreBLEU : 0.103314\n",
      "04/27 11:55:08 PM |\t  G_AB GAB test loss : 4.493781\n",
      "04/27 11:55:08 PM |\t  G_BA GBA test loss : 13.381109\n",
      "04/27 11:55:12 PM |\t  \n",
      "\n",
      "  ----------------epoch:3----------------\n",
      "04/27 11:55:12 PM |\t  total iter:[1503]\n",
      "04/27 11:55:49 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.97419647917603, 'GBA_once_meter': 0.9834745959802107, 'DA_meter': 0.0019333219388499856, 'DB_meter': 0.003338175347766303}\n",
      "04/27 11:55:49 PM |\t  \t\t15.568862275449103%\n",
      "04/27 11:56:32 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9782998019998724, 'GBA_once_meter': 0.9759684349551345, 'DA_meter': 0.006886774613204497, 'DB_meter': 0.004405421815604452}\n",
      "04/27 11:56:32 PM |\t  \t\t35.32934131736527%\n",
      "04/27 11:57:18 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.981830768512957, 'GBA_once_meter': 0.9891183177630106, 'DA_meter': 0.0011850907626053827, 'DB_meter': 0.0012961901551479418}\n",
      "04/27 11:57:18 PM |\t  \t\t55.08982035928144%\n",
      "04/27 11:58:03 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.9992818037668864, 'GBA_once_meter': 1.0034122647661152, 'DA_meter': 0.001171177379684664, 'DB_meter': 0.0013268294715089723}\n",
      "04/27 11:58:03 PM |\t  \t\t74.8502994011976%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_181580/2719241574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n\\n  ----------------epoch:{epoch}----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmy_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycleGAN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#TODO:cycgan.savemodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\train.py\u001b[0m in \u001b[0;36mmy_train\u001b[1;34m(loader, model, total_iter, args, logging, valid_loader, tokenizer, wandb)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainD\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrep_iter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtotal_iter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_pretrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD_A\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'./checkpoint/D_A.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\GitCode\\cycleMT\\cycle.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[1;34m(self, trainD, trainG)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_D_B\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# calculate graidents for D_B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# update D_A and D_B's weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_D_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# update D_A and D_B's weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "    # my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "    #TODO:cycgan.savemodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
