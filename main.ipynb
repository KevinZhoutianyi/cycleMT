{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.getcwd() \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "from test import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import load_dataset,load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch_optimizer as optim\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import logging\n",
    "import sys\n",
    "import transformers\n",
    "from basic_model import *\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import string\n",
    "from cycle import *\n",
    "from train import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.test_iter 498\n",
      "args.rep_iter 99\n"
     ]
    }
   ],
   "source": [
    "if(True):\n",
    "    parser = argparse.ArgumentParser(\"main\")\n",
    "\n",
    "    parser.add_argument('--valid_num_points', type=int,             default = 100, help='validation data number')\n",
    "    parser.add_argument('--train_num_points', type=int,             default = 500, help='train data number')\n",
    "\n",
    "    parser.add_argument('--batch_size', type=int,                   default=3,     help='Batch size')\n",
    "    parser.add_argument('--max_length', type=int,                   default=512,     help='max_length')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int,                          default=0,      help='gpu device id')\n",
    "    parser.add_argument('--G_AB_model_name', type=str,              default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--G_BA_model_name', type=str,              default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--D_A_model_name', type=str,               default='t5-small',      help='model_name')\n",
    "    parser.add_argument('--D_B_model_name', type=str,               default='Onlydrinkwater/T5-small-de-en',      help='model_name')\n",
    "    parser.add_argument('--exp_name', type=str,                     default='CYCLE!',      help='experiment name')\n",
    "    parser.add_argument('--rep_num', type=int,                      default=25,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--rep_iter', type=int,                     default=100,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_iter', type=int,                    default=500,      help='report times for 1 epoch')\n",
    "    parser.add_argument('--test_num', type=int,                     default=4,      help='test times for 1 epoch')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int,                       default=50,     help='num of training epochs')\n",
    "\n",
    "    parser.add_argument('--G_lr', type=float,                       default=0.00001,   help='learning rate for G')\n",
    "    parser.add_argument('--G_weight_decay', type=float,             default=1e-3,   help='learning de for G')\n",
    "    parser.add_argument('--D_lr', type=float,                       default=0.00001,   help='learning rate for D')\n",
    "    parser.add_argument('--D_weight_decay', type=float,             default=1e-3,   help='learning de for D')\n",
    "    parser.add_argument('--lambda_identity', type=float,            default=0.5,   help='')\n",
    "    parser.add_argument('--lambda_A', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_B', type=float,                   default=0,   help='')\n",
    "    parser.add_argument('--lambda_once', type=float,                default=1,   help='')\n",
    "    parser.add_argument('--smoothing', type=float,                  default=0.1,    help='labelsmoothing')\n",
    "\n",
    "\n",
    "    parser.add_argument('--load_D', type=int,                       default=0,      help='load pretrained D')\n",
    "    parser.add_argument('--valid_begin', type=int,                  default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_G', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--train_D', type=int,                      default=1,      help='whether valid before train')\n",
    "    parser.add_argument('--D_pretrain_iter', type=int,              default=100,      help='whether valid before train')\n",
    "\n",
    "\n",
    "    args = parser.parse_args(args=[])#(args=['--batch_size', '8',  '--no_cuda'])#used in ipynb\n",
    "    args.test_iter = args.test_iter//args.batch_size * args.batch_size\n",
    "    args.rep_iter = args.rep_iter//args.batch_size * args.batch_size\n",
    "    print('args.test_iter',args.test_iter)\n",
    "    print('args.rep_iter',args.rep_iter)#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monlydrinkwater\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\GitCode\\cycleMT\\wandb\\run-20220427_175937-3jx518vf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/3jx518vf\" target=\"_blank\">CYCLE!</a></strong> to <a href=\"https://wandb.ai/onlydrinkwater/CYCLEGAN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/onlydrinkwater/CYCLEGAN/runs/3jx518vf?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x299786fbbb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_API_KEY']='a166474b1b7ad33a0549adaaec19a2f6d3f91d87'\n",
    "os.environ['WANDB_NAME']=args.exp_name\n",
    "wandb.init(project=\"CYCLEGAN\",config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 05:59:45 PM |\t  Namespace(D_A_model_name='t5-small', D_B_model_name='Onlydrinkwater/T5-small-de-en', D_lr=0.0001, D_pretrain_iter=100, D_weight_decay=0.001, G_AB_model_name='t5-small', G_BA_model_name='Onlydrinkwater/T5-small-de-en', G_lr=0.0001, G_weight_decay=0.001, batch_size=3, epochs=50, exp_name='CYCLE!', gpu=0, lambda_A=0, lambda_B=0, lambda_identity=0.5, lambda_once=1, load_D=0, max_length=512, rep_iter=99, rep_num=25, smoothing=0.1, test_iter=498, test_num=4, train_D=1, train_G=1, train_num_points=500, valid_begin=1, valid_num_points=100)\n"
     ]
    }
   ],
   "source": [
    "#logging file\n",
    "now = time.strftime(\"%Y-%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "\n",
    "log_format = '%(asctime)s |\\t  %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(\"./log/\", now+'.txt'),'w',encoding = \"UTF-8\")\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "logging.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 05:59:50 PM |\t  Gmodelsize:60.506624MB\n",
      "04/27 05:59:50 PM |\t  Dmodelsize:60.506624MB\n"
     ]
    }
   ],
   "source": [
    "GABmodelname = args.G_AB_model_name\n",
    "GBAmodelname = args.G_BA_model_name\n",
    "DAmodelname = args.D_A_model_name\n",
    "DBmodelname = args.D_B_model_name\n",
    "GABpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GABmodelname)\n",
    "GBApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(GBAmodelname)\n",
    "DApretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DAmodelname)\n",
    "DBpretrained  =  AutoModelForSeq2SeqLM.from_pretrained(DBmodelname)\n",
    "logging.info(f'Gmodelsize:{count_parameters_in_MB(GABpretrained)}MB')\n",
    "logging.info(f'Dmodelsize:{count_parameters_in_MB(DApretrained)}MB')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(GABmodelname)\n",
    "# tokenizerBA = AutoTokenizer.from_pretrained(GBAmodelname)#its the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 05:59:54 PM |\t  Reusing dataset wmt16 (C:\\Users\\kevin\\.cache\\huggingface\\datasets\\wmt16\\de-en\\1.0.0\\0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('wmt16','de-en')\n",
    "train = dataset['train']['translation'][:args.train_num_points]\n",
    "valid = dataset['train']['translation'][args.train_num_points:(args.train_num_points+args.valid_num_points)]\n",
    "\n",
    "\n",
    "train_data = get_Dataset_chaos(train, tokenizer,max_length=args.max_length)\n",
    "train_dataloader = DataLoader(train_data, sampler= RandomSampler(train_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)\n",
    "valid_data = get_Dataset(valid, tokenizer,max_length=args.max_length)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=SequentialSampler(valid_data), \n",
    "                        batch_size=args.batch_size, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleGAN = CycleGAN(args,GABpretrained,GBApretrained,DApretrained,DBpretrained,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/27 06:00:58 PM |\t  GABloss:\t7.180871486663818\n",
      "04/27 06:00:58 PM |\t  GBAloss:\t12.750386238098145\n",
      "04/27 06:00:58 PM |\t  a_decoded[:2]:['Past experience dictates that, as the elected representatives of the European taxpayer, we should, and indeed must, demand financial probity and transparency in the disbursement and auditing of this money, hence our amendments and additions relate to achieving what are known as \"value for money\" indicators in the grant-giving process.', 'Next, we all too often see vast sums of money being spent on projects whose outcomes will necessarily be unclear at the start of the programme period.']\n",
      "04/27 06:00:58 PM |\t  pred_b_decoded[:2]:['The experience of the past shows that, as elected representatives of the European taxpayers, we must demand financial redundancy and transparency in the payment of these funds and the auditing that is involved, and with our amendments and allowances, we want to achieve what can be used as an indicator of the most economically favourable solution in granting grants.', 'Secondly, all too often, huge sums are being spent on projects whose results are simply not clearly assessed at the beginning of the programme period.']\n",
      "04/27 06:00:58 PM |\t  b_decoded[:2]:['Die Erfahrungen der Vergangenheit zeigen, daß wir als die gewählten Vertreter der europäischen Steuerzahler finanzielle Redlichkeit und Transparenz bei der Auszahlung dieser Gelder und der damit verbundenen Rechnungsprüfung fordern sollten, ja müssen. Mit unseren nderungen und Zusätzen wollen wir das erreichen, was bei der Gewährung von Zuschüssen als Indikator für die wirtschaftlich günstigste Lösung dienen kann.', 'Zweitens fließen nur allzu oft riesige Summen in Projekte, deren Ergebnisse sich zu Beginn des Programmzeitraums einfach noch nicht klar abschätzen lassen.']\n",
      "04/27 06:00:58 PM |\t  pred_a_decoded[:2]:['Die Erfahrung der Vergangenheit legt fest, dass wir als gewählte Vertreter des europäischen Steuerzahlers finanzielle Besonnenheit und Transparenz bei der Auszahlung und Prüfung dieses Geldes fordern sollten und müssen. Deshalb beziehen sich unsere nderungsanträge und Ergänzungen auf die Erreichung der so genannten \"Value-for-money\"-Indikatoren im Rahmen des Zuschussverfahrens.', 'Als nächstes sehen wir allzu oft, dass riesige Summen für Projekte ausgegeben werden, deren Ergebnisse zu Beginn des Programmzeitraums notwendigerweise unklar sein werden.']\n",
      "04/27 06:02:05 PM |\t  computing score...\n",
      "04/27 06:02:05 PM |\t  G_AB GAB sacreBLEU : 17.842284\n",
      "04/27 06:02:05 PM |\t  G_BA GBA sacreBLEU : 23.162032\n",
      "04/27 06:02:05 PM |\t  G_AB GAB test loss : 8.635276\n",
      "04/27 06:02:05 PM |\t  G_BA GBA test loss : 11.878961\n",
      "04/27 06:02:05 PM |\t  \n",
      "\n",
      "  ----------------epoch:0----------------\n",
      "04/27 06:02:05 PM |\t  total iter:0\n",
      "04/27 06:03:24 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.7728293465845513, 'GBA_once_meter': 0.7594663175669584, 'DA_meter': 0.2642602976976019, 'DB_meter': 0.2309863589929812}\n",
      "04/27 06:03:24 PM |\t  \t\t38.92215568862276%\n",
      "04/27 06:04:05 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.7582586371537411, 'GBA_once_meter': 0.7630656108711705, 'DA_meter': 0, 'DB_meter': 0}\n",
      "04/27 06:04:05 PM |\t  \t\t58.68263473053892%\n",
      "04/27 06:04:45 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.7594308907335455, 'GBA_once_meter': 0.6073128924225316, 'DA_meter': 0, 'DB_meter': 0}\n",
      "04/27 06:04:45 PM |\t  \t\t78.44311377245509%\n",
      "04/27 06:05:25 PM |\t  {'GB_cycle_meter': 0.0, 'GA_cycle_meter': 0.0, 'GAB_once_meter': 0.7461204781676783, 'GBA_once_meter': 0.7182126785769607, 'DA_meter': 0, 'DB_meter': 0}\n",
      "04/27 06:05:25 PM |\t  \t\t98.20359281437125%\n",
      "04/27 06:05:40 PM |\t  GABloss:\t5.525906562805176\n",
      "04/27 06:05:40 PM |\t  GBAloss:\t24.310115814208984\n",
      "04/27 06:05:40 PM |\t  a_decoded[:2]:['Past experience dictates that, as the elected representatives of the European taxpayer, we should, and indeed must, demand financial probity and transparency in the disbursement and auditing of this money, hence our amendments and additions relate to achieving what are known as \"value for money\" indicators in the grant-giving process.', 'Next, we all too often see vast sums of money being spent on projects whose outcomes will necessarily be unclear at the start of the programme period.']\n",
      "04/27 06:05:40 PM |\t  pred_b_decoded[:2]:['....,..,.,.,.                                                                                                                                                                                                                                                                 ............                                                                                                                  ............   ........    .....   .....    ......    ', '.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ']\n",
      "04/27 06:05:40 PM |\t  b_decoded[:2]:['Die Erfahrungen der Vergangenheit zeigen, daß wir als die gewählten Vertreter der europäischen Steuerzahler finanzielle Redlichkeit und Transparenz bei der Auszahlung dieser Gelder und der damit verbundenen Rechnungsprüfung fordern sollten, ja müssen. Mit unseren nderungen und Zusätzen wollen wir das erreichen, was bei der Gewährung von Zuschüssen als Indikator für die wirtschaftlich günstigste Lösung dienen kann.', 'Zweitens fließen nur allzu oft riesige Summen in Projekte, deren Ergebnisse sich zu Beginn des Programmzeitraums einfach noch nicht klar abschätzen lassen.']\n",
      "04/27 06:05:40 PM |\t  pred_a_decoded[:2]:['Portugais à Portugais L\\'expérience passée dicte que, en tant que représentants élus des contribuables européens, nous devrions, et doit, exiger la probité financière et la transparence dans la déboursation et audit de ces fonds, de sorte que nos amendements et additions concernent l\\'atteinte des indicateurs \"value for money\" in the grant-giving process.', 'Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portugais Portuga']\n"
     ]
    }
   ],
   "source": [
    "if(args.valid_begin==1):\n",
    "    my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "total_iter = [0]  \n",
    "for epoch in range(args.epochs):\n",
    "\n",
    "    logging.info(f\"\\n\\n  ----------------epoch:{epoch}----------------\")\n",
    "    my_train(train_dataloader,cycleGAN,total_iter,args,logging,valid_dataloader,tokenizer,wandb)\n",
    "    # my_test(valid_dataloader,cycleGAN,tokenizer,logging,wandb)\n",
    "    #TODO:cycgan.savemodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65768f95ed3f1ad80799466926a66640b39a99ef5d94bbece814e59aa067606e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
