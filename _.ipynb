{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[13959,  1566,    12,  2968,    10,     1,    37,   511,  1921,    19,\n",
    "            24,    13,     3,    35, 21933,    84,    56,     6,    13,   503,\n",
    "             6,    43,     3,     9, 10710,  1113,     6,   321,    16,  1487,\n",
    "          1208,    11, 20187,  1353,     5,     1,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0],\n",
    "        [13959,  1566,    12,  2968,    10,     1,   101,   103,    59,   241,\n",
    "            12,   143,     8,  1124,    13,  2259,  4131,    21,   128,  1440,\n",
    "         31823,   120,    11,  1172,   135,    21,  1440,   224,    38,  9652,\n",
    "            42,   119, 11811,  1440,     5,     1,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['translate English to German: The second challenge is that of enlargement which will, of course, have a considerable impact, both in budgetary and geographical terms.',\n",
       " 'translate English to German: We do not want to make the conditions of competition worse for some countries unilaterally and improve them for countries such as Austria or other transit countries.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Die zweite Herausforderung besteht in der Erweiterung, die natürlich erhebliche Auswirkungen auf den wirtschaftlichen und geographischen Bereich haben wird.',\n",
       " 'Wir wollen nicht die Wettbewerbsbedingungen für einige Länder einseitig verschlechtern und sie für sterreich oder andere Transitländer verbessern.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([[  316, 15402, 18386,  8962,    16,    74, 30346,     6,    67,  4512,\n",
    "         27554,    15,     3, 27485,   219,   177,     3, 19594,    29,    64,\n",
    "           873, 16407,  1779,  5728,   745,   551,     5,     1,     0,     0],\n",
    "        [ 1185,  6056,   311,    67,     3, 19745,     7, 17391,   218,  4847,\n",
    "         24886,   236, 13584, 10020,   109,   524,  2947,    64,   680,   218,\n",
    "             3,     2, 12852,   401,  2903, 24885, 19881, 22372,     5,     1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Die dritte Herausforderung besteht in der Erweiterung, die ja e Auswirkungen auf unsere Haushaltöffentlichenn und geographischen Bereich haben wird. Das',\n",
       " 'Wir wollen die nur Regelnsbedingungen auf einige Länder einseitig verschlchtern und sie nicht anderesterreich oder andere Transitländer verbessern.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([[  316, 27932, 18386,  8962,    16,    74, 30346,     6,    67,  2662,\n",
    "             3,    15,     3, 27485,   219,  1324, 21068, 17375,    29,    64,\n",
    "           873, 16407,  1779,  5728,   745,   551,     5,     1,     1,   644],\n",
    "        [ 1185,  6056,    67,   790,     3, 28510,     7, 17391,   219,  4847,\n",
    "         24886,   236, 13584, 10020,    40,   524,  2947,    64,   680,   311,\n",
    "          2903,     2, 12852,   401,  2903, 24885, 19881, 22372,     5,     1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./model/G_AB.pt').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,pred_attn  = en(['relating to establishing a framework framework for the development and development development of the European Union and the development development of the European Union and the development of the European Union and the development development of a framework framework framework for the development and development development of the European Union and the development development of a framework framework framework for the development and development development of the European Union and the development development of a framework framework framework for the development and development of the European Union and the development development of the European Union and the development of the European Union, and the development development of a reprehensible forestry.', 'relating to the issue of fraud and fraud fraud. – a report on the issue of fraud and fraud in the EU and the European Commission’s report on the issue of fraud prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention prevention.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label,label_attn  = en(['I have some sympathy with the last speaker: sometimes the Committee on Budgetary Control gets so involved with the important work they are doing, that they are unable to see the wood for the trees.', 'I also welcome the presentation on behalf of the Legal Affairs Committee and the Economic and Monetary Affairs Committee which took a balanced approach to the major and indeed legitimate concerns of the Committee on Budgetary Control about fraud.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(pred,pred_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8662])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpu = torch.rand(1,requires_grad=False)\n",
    "inpu\n",
    "inpuB = torch.rand(1,requires_grad=False)\n",
    "inpuB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9243], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.rand(1,requires_grad=True)\n",
    "W\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = W*inpu + inpuB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors does not require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_53824/206016131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monly_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         inputs, allow_unused, accumulate_grad=False)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
     ]
    }
   ],
   "source": [
    "torch.autograd.grad(outputs=output, inputs=inpu,create_graph=True, retain_graph=True, only_inputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = torch.rand((5, 1, 1),device=torch.device('cuda:0'))\n",
    "onehot_real = torch.ones(5,4,3)\n",
    "alpha = alpha.expand(onehot_real.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3,2,3)\n",
    "b = torch.ones(3,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_53824/3434515637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "torch.sum(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Denn eines ist klar: Selbst wenn wir in der Europäischen Union zu einer ausgezeichneten Regelung kommen, hört der Verkehr nicht an unseren Grenzen, er überschreitet sie.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([[ 7272,   266,     7,   229,  8330,    10,  8262,  1301,   558,    16,\n",
    "           74,     3, 30604,    29,  3545,   170,   645, 23072,    35,  7510,\n",
    "          425,  4714,     6,     3, 20740,    74,   781, 12319,   311,    46,\n",
    "         1324,    29, 23877,     6,     3,    49,   510,   860,    60,   155,\n",
    "           15,    17,   680,     5,     1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ich möchte daher dem Berichterstatter, Herrn Koch, für seine Arbeit zu dieser Frage danken.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([[ 1674,  6509,  8301,   340, 19146,    49, 15679,    49,     6,  8816,\n",
    "           29, 16608,     6,   218,  1834,  5512,   170,     3,  1878,  6973,\n",
    "            3, 23020,     5,     1,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "            0,     0,     0,     0,     0,     0,     0,     0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_penalty = torch.load('./checkpoint/gradient_penalty.pt')\n",
    "gradient = torch.load('./checkpoint/gradient.pt')\n",
    "interpolates = torch.load('./checkpoint/interpolates.pt')\n",
    "onehot_real = torch.load('./checkpoint/onehot_real.pt')\n",
    "fake = torch.load('./checkpoint/fake.pt')\n",
    "output = torch.load('./checkpoint/output.pt')\n",
    "real = torch.load('./checkpoint/real.pt')\n",
    "fake_ = torch.load('./checkpoint/fake_.pt')\n",
    "alpha = torch.load('./checkpoint/alpha.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6736]],\n",
       "\n",
       "        [[0.1732]],\n",
       "\n",
       "        [[0.0100]],\n",
       "\n",
       "        [[0.3951]]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clip(alpha, min=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would like, first of all, to thank the rapporteur for his exceptionally accurate and technical work on the report and, secondly, the Commission for the proposal it has submitted.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([real[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We believe that this is a question that the Commission should take account of the decisions of this Parliament, especially with regard to the mid-term review of these guidelines.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([torch.argmax(fake_[-2],-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We believe that this is a question that the Commission should take account of the decisions of this Parliament, especially with regard to the mid-term review of these guidelines.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([torch.argmax(fake[-2],-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We believe that this is a question that the Commission should take account of the decisions of this Parliament, especially with regard to the mid-term review of these guidelines.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d([torch.argmax(onehot_real[-2],-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "        9.9991e-01, 9.9991e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05, 9.2154e-05,\n",
       "        9.2154e-05], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([  101,   857,    24,    48,    19,     3,     9,   822,    24,     8,\n",
       "         3527,   225,   240,   905,    13,     8,  3055,    13,    48, 12876,\n",
       "            6,   902,    28,  3553,    12,     8,  2076,    18,  1987,  1132,\n",
       "           13,   175,  5749,     5,     1,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0], device='cuda:0'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(interpolates[-2],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(interpolates[:, :,0]>1e-3).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1348],\n",
       "        [0.0587],\n",
       "        [0.0330],\n",
       "        [0.0602]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.1048e-02, 7.9653e-03, 6.0113e-03, 5.5646e-03, 1.9542e-02, 1.3272e-02,\n",
       "        7.2185e-03, 1.3174e-02, 8.0519e-03, 1.2683e-02, 4.3365e-03, 3.6778e-03,\n",
       "        3.5361e-03, 3.4416e-03, 5.2472e-03, 1.0689e-02, 4.5117e-03, 5.3209e-03,\n",
       "        5.8149e-03, 4.3310e-03, 1.0768e-02, 6.1060e-03, 2.5659e-03, 5.4847e-03,\n",
       "        1.3335e-02, 1.1511e-02, 4.0305e-03, 3.6598e-03, 5.6789e-03, 9.4820e-03,\n",
       "        1.5657e-02, 8.7381e-03, 7.0189e-03, 3.3296e-02, 7.5614e-02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1302e+01, 2.4101e+01,\n",
       "        2.0388e+01, 1.9873e+01, 2.0791e+01, 2.4457e+01, 2.1025e+01, 4.8850e+01,\n",
       "        9.2354e+01, 2.7918e+01, 1.2031e+01, 1.7346e+01, 1.7141e+01, 1.1054e+01,\n",
       "        1.7246e+01, 1.7372e+01, 1.8897e+01, 1.8529e+01, 1.7869e+01, 2.4627e+01,\n",
       "        1.3377e+01, 1.4612e+01, 1.4314e+01, 1.5957e+01, 1.5814e+01, 1.5940e+01,\n",
       "        1.6343e+01, 2.2256e+01, 2.0878e+01, 1.8622e+01, 1.8829e+01, 1.9721e+01,\n",
       "        1.5845e+01, 1.8168e+01, 1.4348e+01, 1.5535e+01, 1.3767e+01, 1.6253e+01,\n",
       "        1.7634e+01, 1.9419e+01, 1.7846e+01, 1.6917e+01, 1.7321e+01, 1.9377e+01,\n",
       "        1.9849e+01, 1.9074e+01, 1.7648e+01, 2.0494e+01, 6.9177e+01, 1.8633e+01,\n",
       "        2.4217e+01, 1.7190e+01, 3.3160e+01, 6.9020e+01, 6.6365e+02, 4.6579e+01,\n",
       "        2.9107e+01, 1.4033e+01, 1.9144e+01, 2.2289e+01, 2.6459e+01, 5.0241e+01,\n",
       "        1.5561e+02, 2.2274e+01, 2.3887e+01, 2.3326e+01, 4.8697e+01, 1.6848e+02,\n",
       "        3.0805e+02, 3.0201e+01, 4.0442e+01, 2.1500e+01, 2.2832e+01, 1.4072e+01,\n",
       "        1.6963e+01, 1.5488e+01, 1.9049e+01, 1.5402e+01, 1.6874e+01, 1.9536e+01,\n",
       "        1.6996e+01], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([10273, 31245, 29752, 31930,  9109, 29624, 28294, 22830, 30515, 24889,\n",
       "        13959, 31645, 29692, 16907, 28294, 25355, 20654, 30513,     0,  3527,\n",
       "        11001, 28533, 11433, 26939,     0, 31245, 20654, 24596, 24287, 31245,\n",
       "            0,     0, 29429, 23315, 30759,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0, 13959,  9686, 25355, 18572,\n",
       "        19859, 25355, 29752, 28081, 23782, 27205, 25562, 28800, 25355, 25355,\n",
       "        23054, 29752, 28125, 26478, 27205, 27000, 18977, 27000, 18977, 26478,\n",
       "        25355, 20911, 28221, 27205, 27136, 27205, 27205, 29351, 27416, 25355,\n",
       "        26944, 26478, 26944, 27205, 25355, 25355, 30299, 30392, 30392, 19139,\n",
       "        25562, 27000, 28237, 24287, 31507, 28852, 29752, 25355, 29752, 29752,\n",
       "        31507, 31507, 29752, 28182, 29752, 29752, 29752, 29752, 31507, 30759,\n",
       "        29752, 28182, 29752, 31507, 31894, 29752, 29752, 29752, 10658, 12810,\n",
       "        24777, 31502, 30121, 21603,  4697, 31526, 28085], device='cuda:0'))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(gradient[-2],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40464.6172, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((gradient.norm(2, dim=1) - 1) ** 2).mean(-1)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 2, 1]]), tensor([[1, 1, 1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en(['周'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7102,    1]]), tensor([[1, 1]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en(['hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   3,   29,   23,   26,  210,   29, 6146,   29,    9,   23,  210,   26,\n",
       "          1024,   23,  210,  107,   26,    9,    1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en(['nidwnaidnaiwdhaiwhda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset,load_metric\n",
    "load_dataset(\"bible_para\", lang1=\"de\", lang2=\"en\").shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d33c3b0ef123e851f98887a8750ca7da758e4ff258891935cfe6ff9c0394387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
